<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Vue 面试题]]></title>
    <url>%2F2019%2F09%2F08%2FVue-%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[都是一些最为基础的面试题 1. Vue 的源码结构12345678910111213141516171819202122232425262728293031323334├── config // 项目开发环境配置│ └── index,js // 项目打包部署配置├── src // 源码目录│ ├── components // 公共组件| | ├── header.vue // 公共组件页面头部| | ├── footer.vue // 公共组件页面尾部| | └── index.js // 加载各种公共组件│ ├── config // 路由配置和程序的基本信息配置| | └── routes.js // 配置页面路由│ ├── css // 各种 css 文件| | └── common.css // 全局通用 css│ ├── iconfont // 字体图标│ ├── images // 公共图片│ ├── less // 各种 less 文件│ | └── common.less // 全局通用 lesss│ ├── pages // 页面组件| | ├── home| | ├── index| | ├── login| | └── signout│ ├── store // vuex 的状态管理| | ├── index.js // 加载各种 store 模块| | └── user.js // 用户 store│ ├── template // 各种 html 文件| | └── index.html // 程序入口 html│ ├── util // 公共的 js 方法│ ├── App.vue // 页面入口文件│ ├── main.js // 程序入口文件，加载各种公共组件├── .babelrc // ES6 语法编译配置├── gulpfile.js // 启动、打包、部署、自动化构建├── webpack.config.js // 打包配置├── server.js // 代理服务器配置├── README.md├── package.json // 配置项目相关信息，通过执行 npm init 创建 2. 对于 MVVM 的理解MVVM 也就是是 Model - View - ViewModel： Model：代表数据模型，也可以在 Model 中定义数据修改和操作的业务逻辑 View：代表 UI 组件，负责将数据模型转化成 UI 展现出来 ViewModel：监听模型数据的改变和控制视图行为、处理用户交互，简单理解就是一个同步 View 和 Model 的对象，连接 Model 和 View 在 MVVM 架构下，View 和 Model 之间并没有直接的联系，而是通过 ViewModel 进行交互，Model 和 ViewModel 之间的交互是双向的，因此 View 数据的变化会同步到 Model 中，而 Model 数据的变化也会立即反应到 View 上。 ViewModel 通过双向数据绑定把 View 层和 Model 层连接了起来，而 View 和 Model 之间的同步工作完全是自动的，无需人为干涉，因为开发者只需关注业务逻辑，不需要手动操作 DOM，不需要关注数据状态的同步问题，复杂的数据状态维护完全由 MVVM 来统一管理。 3. Vue 的生命周期 beforeCreate：创建前，在数据观测和初始化事件还未开始 created：创建后，完成数据观测，属性和方法的运算，初始化时间，$el 属性还没有显示出来 beforeMount：载入前，在挂在开始之前被调用，相关的 render 函数首次被调用： 编译模板 把 data 里面的数据和模板生成 html 注意此时还没有挂载 html 到页面上 mounted：载入后，在 el 被新创建的 vm.$el 替换，并挂载到实例上去之后的调用： 用上面编译好的 html 内容替换 el 属性指向的 DOM 对象 完成模板中的 html 渲染到 html 页面中 此过程中进行 ajax 交互 beforeUpdate：更新前，在数据更新之前调用，发生在虚拟 DOM 重新渲染和打补丁之前，可在该钩子中进一步的更改状态，不会触发附加的重渲染过程 updated：更新后，在由于数据更改导致的虚拟 DOM 重新渲染和打不定之后调用。调用时，组件 DOM 已经更新，所以可以执行依赖于 DOM 的操作。然而在大多数情况下，应该避免在此期间更改状态，因为这可能会导致更新无线循环，该钩子在服务器端渲染期间不被调用 beforeDestroy：销毁前，此时实例还可以使用 destroyed：销毁后，调用后，所有的时间监听器会被移除，所有的子实例也会被销毁。该钩子在服务器端渲染期间不被调用 什么是 Vue 生命周期Vue 实例从创建到销毁的过程，从开始创建、初始化数据、编译模板、挂载 DOM -&gt; 渲染、更新、更新 -&gt; 渲染、销毁等一系列过程 Vue 生命周期的作用它的生命周期中有多个事件钩子，让我们在控制整个 Vue 实例的过程时更容器形成好的逻辑 有几个阶段创建前后、载入前后、更新前后、销毁前后 第一次页面加载会触发哪几个钩子前 4 个 DOM 渲染在那个周期中mounted 4. Vue 实现数据双向绑定的原理 Object.defineProperty() Vue 实现数据双向绑定主要是： 采用 数据劫持结合发布订阅模式 的方式，通过 Object.defineProperty() 来劫持各个属性的 setter、getter 方法 在数据变动时发布消息给订阅者，触发响应的监听回调 当把一个普通的 js 回想传给 Vue 实例来作为它的 data 选项时，Vue 将遍历它的属性，用 Object.defineProperty 将他们转化为 setter 和 getter，用户看不到，但是内部让 Vue 追踪依赖，在属性被访问和修改时通知变化 js 实现的简单双向绑定 12345678910111213141516171819202122&lt;body&gt; &lt;div id="app"&gt; &lt;input type="text" id="txt"&gt; &lt;p id="show"&gt;&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;script type="text/javascript"&gt; var obj = &#123;&#125; Object.defindeProperty(obj, 'txt', &#123; get: function () &#123; return obj &#125;, set: function (newValue) &#123; document.getElementsById('text').value = newValue document.getElementsById('show').innerHTML = newValue &#125; &#125;) document.addEventListener('keyup', function (e) &#123; obj.txt = e.target.value &#125;)&lt;/script&gt; 5. Vue 组件间的参数传递父组件给子组件传值 父传子：子部件通过 props 方法接受数据 子传父：$emit 方法传递参数 非父子组件，兄弟组件 eventsBus，就是创建一个事件中心，相当于中转站，用来传递和接受事件（适用于小项目） vuex 6. Vue 路由的实现hash 模式 在浏览器中符号 #，# 以及 # 后面的字符称之为 hash，用 window.location.hash 读取 特点： hash 虽然在 URL 中，但不被包括在 HTTP 请求中 用来知道浏览器动作，对服务端安全无用，hash 不会冲加载页面 hash 模式下，仅 hash 符号之前的内容会包含在请求中，因此对于后端来说，即使没有做到对路由的全覆盖，也不会 404 hisroty 模式history 采用 HTML5 新特性，提供了两个新方法：pushState()、replaceState() 可以对浏览器历史记录栈进行修改，以及 popState 事件的监听到状态变更。 history 模式下，前端的 URL 必须和实际向侯丹发起请求的 URL 一致，后端如果缺少对特定路由的处理，就会 404。 Vue-Router 官网里如此描述： 不过这种模式要好玩，还需要后台配置支持……所以呢，你要在服务器端加载一个覆盖所有情况的候选资源：如果 URL 匹配不到任何静态资源，应该返回同一个 index.html，这个页面就是你 APP 依赖的页面 7. 前端三巨头的区别与 Angular JS相同点： 都支持指令：内置指令和自定义指令 都支持过滤器：内置和自定义 都支持双向数据绑定 都不支持低端浏览器 不同点： Angular 的学习成本高，比如增加了 Dependency Injection 特性，而 Vue 本身更简单 性能上，Angular 对数据做脏检查，Watcher 越多越慢；而 Vue 使用局域依赖追踪的观察，而且异步 更新，所有数据都是独立触发 与 React相同点： React 采用特殊的 JSX 语法，Vue 在组件开发中推崇编写 .vue 的特殊文件格式，对文件内容都有一定约定 两者都需要编译后使用 中心思想相同：一切都是组件，组件实例之间可以嵌套 都提供合理的钩子函数 都不内置 ajax，router 等功能的核心包，而是通过插件的方式加载 在组件开发中都支持 mixins 的特性 不同点： React 采用 Virtual DOM 会对渲染出来的结果做脏检查 vue 在模板中提供了指令，过滤器等，可以非常方便、快捷的操作 Virtual DOM 8. Vue 路由的钩子函数首页可以控制导航跳转，beforeEach、afterEach 等，一般用于 title 修改，一些需要登录才能调整页面的重定向功能。 beforeEach 主要参数： to：目标路由对象 from：正要离开的路由 next：function 一定要调用该方法 resolve 这个钩子。执行效果依赖 next 方法的调用参数，可以控制网页的跳转 9. Vuex只用来读取的状态集中放在 store 中，改变状态的方式是提交 mutations，这个是同步的事物；异步逻辑应该封装在 action 中。 在 main.js 引入 store，注入。 应用场景：单页面应用中，组件之间的状态、音乐播放、登录状态、加入购物车 statevuex 使用单一状态树，即每个应用仅仅包含一个 store 实例，但单一状态树和模块化并不冲突。存放的数据状态，不可以直接修改里面的数据 mutationsmutations 定义的方法动态修改 vuex 的 store 中的状态或数据 getters类似 vue 的计算属性，主要用来过滤一些数据 actions可以理解为通过将 mutations 里面处理数据的方法变成可异步的处理数据的方法，简单的说就是异步处理操作数据。view 层通过 store.dispath 来分发 action 123456789101112131415const store = new Vue.Store(&#123; state: &#123; count: 0 &#125;, mutations: &#123; increment (state) &#123; state.count++ &#125; &#125;， actions: &#123; increment (context) &#123; context.commit('increment') &#125; &#125;&#125;) modules项目特别复杂的时候，可以让每一个模块拥有自己的 state、mutation、action、getters，是结构非常清晰，便于管理： 1234567891011121314151617181920const moduleA = &#123; state: &#123;...&#125;, mutations: &#123;...&#125;, actions: &#123;...&#125;, getters: &#123;...&#125;&#125; const moduleB = &#123; state: &#123;...&#125;, mutations: &#123;...&#125;, actions: &#123;...&#125;, getters: &#123;...&#125;&#125;const store = new Vuex.Store(&#123; modules: &#123; a: moduleA, b: modulesB &#125;&#125;) 10. vue-cli 自定义指令创建局部指定 12345678910111213141516171819var app = new Vue(&#123; el: '#app', data: &#123; &#125;, // 创建命令，可多个 directives: &#123; // 指令名称 dir1: &#123; inserted(el) &#123; console.log(el); console.log(arguments); el.style.width = '200px'; el.style.height = '200px'; el.style.background = '#000'; &#125; &#125; &#125;&#125;) 全局指令 12345Vue.directive('dir2', &#123; inserted(el) &#123; console.log(el); &#125;&#125;) 指令使用 1234&lt;div id="app"&gt; &lt;div v-dir1&gt;&lt;/div&gt; &lt;div v-dir2&gt;&lt;/div&gt;&lt;/div&gt; 11. 自定义过滤器1234&lt;div id="app"&gt; &lt;input type="text" v-model="msg"/&gt; &#123;&#123;msg| capitalize&#125;&#125;&lt;/div&gt; 12345678910111213var vm = new Vue(&#123; el: "#app", data: &#123; msg: '' &#125;, filters: &#123; capitaliza: function (value) &#123; if (!value) return '' value = value.toString() return value.charAt(0).toUpperCase() + value.slice(1) &#125; &#125;&#125;) 全局 12345Vue.filter('capitalize', function (value) &#123; if (!value) return '' value = value.toString() return value.charAt(0).toUpperCase() + value.slice(1)&#125;) 12. Keep-alivekeep-alive 是 vue 内置的一个组件，可以是被包含的组件保留状态，或避免重新渲染。 在 vue 2.1.0 版本之后，keep-alive 新加入了两个属性: include (包含的组件缓存) 与 exclude (排除的组件不缓存，优先级大于 include) 。 使用方法 12345&lt;keep-alive inclue='include_components' exclude="exclude_components"&gt; &lt;component&gt; &lt;!-- 该组件是否缓存取决于 inclue 和 exclude 属性 --&gt; &lt;/component&gt;&lt;/keep-alive&gt; 参数 include：字符串或者正则表达式，只有名称匹配的组件会被缓存 exclude：字符串或者正则表达式，任何名称匹配的组件都不会被缓存 include 和 exclude 的属性允许组件有条件地缓存。二者都可以用,分隔字符串、正则表达式、数组 当使用正则或者是数组时，要记得使用v-bind 使用示例 1234567891011121314&lt;!-- 逗号分隔字符串，只有组件a与b被缓存。 --&gt;&lt;keep-alive include="a,b"&gt; &lt;component&gt;&lt;/component&gt;&lt;/keep-alive&gt;&lt;!-- 正则表达式 (需要使用 v-bind，符合匹配规则的都会被缓存) --&gt;&lt;keep-alive :include="/a|b/"&gt; &lt;component&gt;&lt;/component&gt;&lt;/keep-alive&gt;&lt;!-- Array (需要使用 v-bind，被包含的都会被缓存) --&gt;&lt;keep-alive :include="['a', 'b']"&gt; &lt;component&gt;&lt;/component&gt;&lt;/keep-alive&gt; 13. 其他简单问题css 只在当前组件起作用 在 style 标签中写入 scoped：&lt;style scoped&gt;&lt;/style&gt; v-if 和 v-show 的区别 v-if 按条件是否渲染，v-show 是 display 的 block 或者 none $route 和 $router 的区别 $route 是 路由信息对象，包括 path、params、hash、query、fullPath、matched、name 等路由信息参数。而 $router 是 路由实例 对象，包括了路由的跳转方法，钩子函数等 vue 的核心 数据驱动、组件系统 常用命令 v-for、v-if、v-bind、v-on、v-show、v-else 常用修饰符 prevevt： 提交时间不在重载页面 stop：阻止时间冒泡 self：当时间发生在该元素本身而不是子元素时触发 capture：事件监听，事件发生的时候会调用 v-on 可以绑定多个方法吗 可以 vue 中 key 值的作用 当 vue 用 v-for 正在更新已渲染过的元素列表时，默认用 就地服用 策略 如果数据项的顺序被改变，vue 将不会移动 DOM 元素来匹配数据项的顺序，而是简单复用此处每个元素，并确保它在特定的索引下显示已被渲染过的每个元素 key 的作用主要是为了更高效的更新虚拟 DOM 什么是 vue 的计算属性 在模板中放入太多的逻辑会让模板过重而且难以维护，在需要对数据进行复杂处理时，且可能多次使用的情况下，尽量计算属性的方法： 使得数据处理结构清晰 依赖于数据，数据更新，处理结果自动更新 急速那属性内部 this 指向 vm 实例 在 template 调用时，直接写计算属性名即可 常用的是 getter 方法，获取数据，也可以使用 set 方法改变数据 相较于 methods，不管依赖的数据不变，methods 都会重新计算，但是依赖数据不变的时候 computed 从缓存中获取，不会重新计算 vue 单页面应用优缺点 优点：vue 的目标是通过尽可能简单的 API 实现响应的数据绑定和组合的视图组件，核心是一个响应的绑定数据系统。MVVM、数据驱动、组件化、轻量、简洁、高效、快速、模块友好。 缺点：不支持低版本的浏览器，最低只支持到IE9；不利于SEO的优化（如果要支持SEO，建议通过服务端来进行渲染组件）；第一次加载首页耗时相对长一些；不可以使用浏览器的导航按钮需要自行实现前进、后退。 怎么定义 vue-router 的动态路由？怎么后去传过来的值 在 router 目录下的 index.js 文件中，对 path 属性加上 /:id，使用 router 对象的 params.id 获取]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring 面试题（一）]]></title>
    <url>%2F2019%2F09%2F05%2FSpring-%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1. 什么是 Spring 框架 Spring 是一种轻量级开发框架，旨在提高开发人员的开发效率以及系统的可维护性。 我们一般所说的 Spring 一般是指 Spring Framework，它是很多模块的集合，使用这些模块可以很方便的协助我们进行开发。 这些模块是：核心容器、数据访问、Web、AOP、工具、消息和测试模块。比如：Core Container 中的 Core 组件是 Spring 所有组件的核心，Beans 组件和 Context 组件是实现 IOC 和依赖注入的基础，AOP 组件用来实现面向切面编程。 Spring 的 6 个特征： 核心技术：依赖注入、AOP、事件（events）、资源、i18n、验证、数据绑定、类型转换、SpEL 测试：模拟对象、TestContext 框架、Spring MVC 测试、WebTestClient 数据访问：事务、DAO 支持、JDBC、ORM、编组 XML Web 支持：Spring MVC 和 Spring WebFlux Web 框架 集成：远程处理、JMS、JCA、JMX、电子邮件、任务、调度、缓存 语言：Kotlin、Groovy、动态语言 2. 列举一些重要的 Spring 模块 Spring 4.x Spring 5.x Spring Core：基础，可以说 Spring 其他所有功能都需要依赖于该类库，主要提供 IOC 依赖注入功能 Spring Aspects：该模块为与 AspectJ 的集成提供支持 Spring AOP：提供了面向切面的编程实现 Spring JDBC：Java 数据库连接 Spring JMS：Java 消息服务 Spring ORM：用于支持 Hibernate 等 ORM 工具 Spring Web：为创建 Web 应用程序提供支持 Spring Test：提供了对 JUnit 和 TestNG 测试的支持 3. IOC 和 AOPIOCIOC（Inverse of Control）是一种设计思想，就是将原本在程序中手动创建对象的控制权，交由 Spring 框架来管理。IOC 在其他语言中也有应用，并非 Spring 特有。IOC 容器是 Spring 用来实现 IOC 的载体，IOC 实际上就是个 Map(key, value)，Map 中存放的是各种对象。 IOC 容器就像是一个工厂一样，当我们需要创建一个对象的时候，只需要配置好配置文件或注解即可，完全不用考虑对象是如何被创建出来的。 Spring IOC 的初始化过程 AOP AOP（Aspect-Oriented Programing）能够将那些与业务无关，却为业务模块所共同调用的逻辑或责任（如事务处理、日志管理、权限控制等）封装起来，便于减少系统的重复代码，降低模块间的耦合，并有利于未来的可拓展性和可维护性。 Spring AOP 就是基于动态代理的，如果要代理的对象，实现了某个接口，那么 Spring AOP 会使用 JDK Proxy，去创建代理对象，而对于没有实现接口的对象，就无法使用 JDK Proxy 去进行代理了，这时候 Spring AOP 会使用 Cglib 生成一个被代理对象的子类来作为代理： 当然我们也可以使用 AscpectJ、Spring AOP 已经集成了 AspectJ，AspectJ 应该算的上是 Java 生态中最完整的 AOP 框架了。 使用 AOP 之后我们可以把一些通用功能抽象出来，在需要的地方直接使用即可，这样大大简化了代码量。我们需要增加新功能时也方便，这样也提高了系统扩展性。日志功能、事务管理等等场景都用到了 AOP。 4. Spring AOP 和 AspectJ AOP 的区别Spring AOP 属于运行时增强，而 AspectJ 是编译时增强。Spring AOP 基于代理，而 AspectJ 基于字节码操作。 Spring AOP 更简单，但是功能更少。 如果我们的切面比较少，那么两者的性能差异不大。但是，当切面太多的话，最好选择 AspectJ，它比 Spring AOP 快很多。 5. Bean 的生命周期 Bean 的建立：容器寻找 Bean 的定义信息并将其实例化，也就是 new 一个对象 属性注入：使用依赖注入，Spring 按照 Bean 定义信息配置 Bean 所有属性，相当于调用 setter 方法 如果这个 Bean 实现了 BeanNameAware 接口，会调用它实现的 setBeanName(String beanId) 方法 如果这个 Bean 实现了 BeanFactoryAware 接口，会调用它实现的 setBeanFactory()，传递的是 Spring 工厂本身（可以用这个方法获取到其他 Bean） 如果这个 Bean 实现了 ApplicationContextAware，会调用 setApplicationContext(ApplicationContext app)，传入 Spring 上下文，该方法同样可以实现步骤 4，但是比步骤 4 好，因为 ApplicaitonContext 是 BeanFactory 的子接口，有更多的实现方法 如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postProcessBeforeInitialization(Object obj, String s) 方法，BeanPostProcessor 经常被作用作是 Bean 内容的更改，并且由于这个实在 Bean 初始画结束时调用 After 方法，也可用于内存或缓存技术 如果设置了 initializingBean 接口，会调用实现的 afterPropertiesSet() 方法 如果这个 Bean 在 Spring 配置文件中配置了 init-method 属性会自动调用其配置的初始化方法 如果这个 Bean 关联了 BeanPostProcessor 接口，将会调用 postAfterInittialzation(Object obj, String s) 方法 容器关闭，当 Bean 不再被需要，会经过清理阶段，如果 Bean 实现了 DisposableBean 接口，会调用其实现的 destroy 方法，如果这个 Bean 的 Spring 配置中配置了 destroy-method 属性，会自动调用其配置的销毁方法 6. Bean 的作用域 singleton：唯一 bean 实例，Spring 中的 bean 默认都是单例的 prototype：每次请求都会创建一个新的 bean 实例 request：每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP Request 中有效 session：每一次 HTTP 请求都会产生一个新的 bean，该 bean 仅在当前 HTTP Session 中有效 global-session：全局 session 作用域，仅仅在基于 portlet 的 web 应用内才有意义，Spring 5.x 中已经没有了。portlet 是能够生成语义代码（例如：HTML）片段的小型 Web 插件。他们基于 portlet 容器，可以像 servlet 一样处理 HTTP 请求。但是，与 servlet 不同，每个 portlet 都有不同的会话 7. 单例 bean 的线程安全问题单例 Bean 存在线程安全问题，主要是因为当多个线程操作同一个对象的时候，对这个对象的非静态成员变量的写操作会存在线程安全问题。 在 bean 对象中尽量避免定义可变的成员变量（不太可能） 在类中定义一个 ThreadLocal 成员变量，将需要的可变成员变量保存在 ThreadLocal 中 8. Spring MVCMVC 是一种设计模式，Spring MVC 是一款很优秀的 MVC 框架。Spring MVC 可以帮助我们进行更简介的 Web 开发，并且它天生与 Spring 框架集成。Spring MVC 下我们一般把后端项目分为 Service 层、Dao 层、Entity 层、Controller 层，返回数据给前台。 8.1 Spring MVC 工作原理典型回答 用户发送请求到后端，后端的前端控制器接收后根据请求 URL 到映射器查找处理器和执行链并返回，前端控制器通过适配器执行处理器，然后接受处理器返回的 ModelAndView 对象，前端控制器调用视图解析器解析 ModelAndView，根据返回的结果去响应用户请求或渲染视图。 详细流程 用户向服务器发送请求，请求被 Spring 前端控制器 DispatcherServlet 捕获 DispatcherServlet 对请求 URL 进行解析，得到请求资源标识符 URI。然后根据该 URI，调用处理器映射器 HandlerMapping 获得该 Handler 配置的所有相关的对象（包括 Handler 对象以及 Handler 对象对应的拦截器），最后以 HandlerExecutionChain 对象的形式返回 DispatcherServlet 根据获得的处理器 Handler，选择一个合适的 HandlerAdapter 。（适配器模式，如果成功获得 HandlerAdapter 后，将会开始执行拦截器的 preHandler(..) 方法） 提取 request 中的数据模型，填充入 Handler，开始执行 Handler（Controller），在填充 Handler 的入参过程中，根据配置不同，Spring 会做一些额外的工作： HttpMessageConveter：将请求消息（如：json、xml）转化为一个对象，将对象转换为指定的响应信息 数据转换：对请求消息进行数据转换，如 String 转换为 Integer、Double 等 数据格式化：对请求消息进行数据格式化，如将字符串转换成格式化数字或格式化日期等 数据验证（如果有）：验证数据的有效性（长度、格式等），验证结果存储到 BindingResult 或 Error 中 处理器 Handler 执行完后，向前端控制器 DispatcherServlet 返回一个 ModelAndView 对象 根据返回的 ModelAndView 对象，选择一个合适的视图解析器 ViewResolver，（必须是已经注册到 Spring 中的）返回给 DispatcherServlet 视图解析器 ViewResolver 结合 Model 和 View，来渲染视图 View 将渲染结果返回给客户端 8.2 Spring MVC 中的设计模式 工程设计模式：Spring 使用工厂模式通过 BeanFactory、ApplicationContext 创建 Bean 对象 代理设计模式：Spring AOP 单例设计模式：Bean 都是单例的 模板方法模式：Spring 中的 JDBCTemplate、HibernateTemplate 等各种以 Template 结尾的对数据库操作的类 包装器设计模式：需要连接多个数据库 观察者模式：Spring 中的事件驱动模型 适配器模式：Spring AOP 中的增强或通知，Controller 9. Spring 中的事务9.1 隔离级别 TransactonDefinition 接口中定义了五个表示隔离级别的常量 ISOLATION_DEFAULT：使用后端数据库默认的隔离级别 ISOLATION_READ_UNCOMMITED ISOLATION_READ_COMMITED ISOLATION_REPEATABLE_READ ISOLATION_SERIALIZABLE 9.2 传播行为支持当前事务的情况： TransactionDefinition.PROPAGATION_REQUIRED： 如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。 TransactionDefinition.PROPAGATION_SUPPORTS： 如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。 TransactionDefinition.PROPAGATION_MANDATORY： 如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。（mandatory：强制性） 不支持当前事务的情况： TransactionDefinition.PROPAGATION_REQUIRES_NEW： 创建一个新的事务，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NOT_SUPPORTED： 以非事务方式运行，如果当前存在事务，则把当前事务挂起。 TransactionDefinition.PROPAGATION_NEVER： 以非事务方式运行，如果当前存在事务，则抛出异常。 其他情况： TransactionDefinition.PROPAGATION_NESTED： 如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于 TransactionDefinition.PROPAGATION_REQUIRED。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 规范]]></title>
    <url>%2F2019%2F09%2F05%2FMySQL-%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[1. 数据库命名规范 所有数据库对象名称必须使用小写字母并用下划线分割 禁止使用保留字段 命名要能做到见名识意，并且最后不要超过 32 个字符 临时库表必须以 tmp_ 为前缀，以日期为后缀 备份表必须使用 bak_ 为前缀并以日期（时间戳）为后缀 所有存储相同数据的列名和列类型必须一致 2. 数据库基本设计规范1. 所有表必须使用 InnoDB 存储引擎 没有特殊要求（即 InnoDB 无法满足的功能如：列存储，存储空间数据等）的情况下，所有表必须使用 InnoDB 存储引擎（MySQL 5.5 之前默认使用 MyISAM，5.6 以后默认的为 InnoDB）。 InnoDB 支持事务，支持行级锁，更好的恢复性，高并发下性能更好。 2. 数据库和表的字符集统一使用 UTF8 兼容性更好，统一字符集可以避免由于字符集转换产生的乱码，不同的字符集进行比较前需要进行转换会造成索引失效，如果数据库中有存储 emoji 表情的需要，字符集需要采用 utf8mb4 字符集。 3. 所有字段和表都需要添加注释 使用 comment 从句添加表和列的备注，从一开始就进行数据字典的维护。 4. 尽量控制表单数据量的大小，建议控制在 500 万以内 500 万并不是 MySQL 数据库的限制，过大会造成修改表结构，备份，恢复都会有很大的问题。 可以用历史数据归档（应用于日志数据），分库分表（应用于业务数据）等手段来控制数据量大小。 5. 谨慎使用 MySQL 分区表 分区表在物理上表现为多个文件，在逻辑上表现为一个表 谨慎选择分区键，跨分区查询效率可能更低 建议采用物理分表的方式管理大数据 6. 尽量做到冷热数据分离，减小表的宽度 MySQL 限制每个表最多存储 4096 列，并且没一行数据的大小不能超过 65535 字节 减少磁盘 I/O，保证热数据的内存缓存命中率（表越宽，加入到内存缓存中的速度越慢，占用内存也更大） 更有效的利用缓存 经常一起使用的列放到一个表中 7. 禁止在表中建立预留字段 预留字段的命名很难做到见名识义 预留字段无法确认存储的数据类型，所以无法选择合适的类型 对预留字段类型的修改，会对表进行锁定 8. 禁止在数据库中存储文件，图片等大的二进制数据 通常文件很大，会短时间内造成数据量快速增长，数据库进行数据库读取时，通常会进行大量的随机 IO 操作，文件很大时，IO 操作很耗时。 通常存储于文件服务器，数据库只存储文件地址信息 9. 禁止在线上做数据库压力测试 10. 禁止从开发环境，测试环境直接生成环境数据库 3. 数据库字段设计规范 优先选用符合条件的最小数据类型 避免使用 TEXT，BLOB 数据类型，最常见的 TEXT 类型可以存储 64k 的数据 避免使用 ENUM 类型 尽可能把所有列定义为 NOT NULL 使用 TIMESTAMP（4 个字节）或 DATETIME （8 个字节）存储时间 同财务相关的金额类数据必须使用 DECIMAL 类型 4. 索引设计规范 限制单表上的索引个数，一般不超过 5 个 禁止给表中的每一列都建立单独索引 每个 InnoDB 表必须有主键 常见建立索引的列： 出现在 SELECT、UPDATE、DELETE 语句的 WHERE 从句中的列 包含在 GROUP BY、ORDER BY、DISTINCT 中的字段 通常将上面两种情况的字段建立联合索引 多表 JOIN 的关联列 选择索引的顺序： 区分度最高的放在联合索引的最左侧（区分度 = 列中不同值的数量 / 列的总行） 尽量把字段长度小的列放在最左侧 使用最频繁的列放在左侧 避免重复索引和冗余索引： 重复索引：primary key(id)、index(id)、unique index(id) 冗余索引：index(a, b, c)、index(a, b)、index(a) 对于频繁的查询优先考虑覆盖索引 索引 SET 规范： 尽量避免使用外键约束 外键会降低父表和子表的写操作而降低性能 尽量在业务功能上实现外键功能 5. SQL 开发规范 建议使用预编译语句进行数据库操作 避免数据类型的隐式转换，会带来索引失效 SELECT name, phone FROM customer WHERE id = &#39;111&#39; 充分利用表上已经创建的索引 数据库设计时，要考虑后续的扩展 程序连接不同的数据库使用不同的账号，进行跨库查询 为数据库迁移和分库分表留出余地 降低业务耦合 避免权限过大而产生的安全风险 禁止使用 SELECT * 禁止使用不含字段的 INSERT 语句 错误：INSERT INTO t VALUES(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) 正确：INSERT INTO t(c1, c2, c3) VALUES (&#39;a&#39;, &#39;b&#39;, &#39;c&#39;) 避免使用子查询，因为无法使用索引 避免使用 JOIN 关联太多的表 减少同数据库的交互操作 对同一列进行 OR 判断时，使用 IN 替代 OR，因为 IN 能有效的利用索引 禁止使用 ORDER BY rand() 进行随机排序 WHERE 从句中禁止对列进行函数转换和计算： 错误：WHERE date(create_time) = &#39;20191001&#39; 正确：WHERE create_time &gt;= &#39;20191001&#39; AND create_time &lt; &#39;20190102&#39; 在明显不会有重复值时使用 UNION ALL 而不是 UNION UNION 会把两个结果集的所有数据放到临时表中再去进行去重操作 UNION ALL 不会对结果集进行去重操作 拆分复杂的大 SQL 分为多个小 SQL 6. 数据库操作行为规范超过 100 万行的批量写操作（UPDATE、INSERT、DELETE）要分批多次进行操作 大批量操作可能会造成严重的主从延迟 binlog 日志为 row 格式时会产生大量日志 避免产生大事务操作 对于大表使用 pt-online-schema-change 修改表结构 避免大表修改产生的主从延迟 避免在对表字段进行修改时进行锁表 禁止为程序使用的账号赋予 super 权限 当达到最大连接数限制时，还运行一个有 super 权限的用户连接 super 权限只能留给 DBA 处理问题的账号使用 程序使用数据库账号只能在一个 DB 下使用，不准跨库 程序使用的账号原则上不准有 DROP 权限]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 面试题（一）]]></title>
    <url>%2F2019%2F09%2F05%2FMySQL-%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1. 什么是 MySQL？MySQL 是一种关系型数据库，在 Java 企业级开发中十分常用，因为 MySQL 是开源免费的，并且方便扩展。阿里巴巴数据库系统也大量用到了 MySQL，因此它的稳定系是有保障的。 MySQL 是开源的，因此任何人都可以在 GPL（General Public License） 的许可下下载并根据个性化的需求对其进行修改。 2. 事务相关2.1 什么是事务？事务是逻辑上的一组操作，要么都执行，要么都不执行。 2.2 事务的四大特性 原子性：事务最小的执行单位，不允许分割 一致性：执行事务前后，数据保持一致，多个事务对同一个数据的读取结果是相同的 隔离性：并发访问数据时，一个用户的事务不被其它事务干扰，各个并发事务之间数据库是独立的 持久性：一个事务被提交后，它对数据库中数据的改变是持久的，即使数据库发生故障也不会对其影响 2.3 并发事务带来的影响 脏读：一个事务读取到了另一个事务正在修改还没有提交的数据 不可重复读：一个事务多次读取同一数据，在读取过程中，另一个事务对其进行了修改，造成了多次读取数据不一样 幻读：在读取过程中，另外的事务插入了一些数据，就会发现了一些好像不存在的东西 丢失修改：两个事务同时修改一个数据，都是 -1，本来结果应该是两个-1，也就是 -2，但是却是 -1 2.4 MySQL 事务的隔离级别 读未提交：最低的隔离级别，允许读取未提交的数据 读已提交：允许读取事务已经提交的数据 可重复读：对同一字段的多次读取结果是一致的，除非数据被本身事务修改 串行化：最高的隔离级别，完全服从 ACID，所有事务依次执行 隔离级别 脏读 不可重复读 幻读 READ-UNCOMMITED √ √ √ READ-COMMITED × √ √ REPEATABLE-READ × × √ SERIALIZABLE × × × MySQL InnoDB 默认支持的是 REPEATABLE-READ 123456mysql&gt; SELECT @@tx_isolation+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+ 与 SQL 标准不同的地方在于 InnoDB 存储引擎在 REPEATABLE-READ 事务隔离级别下使用的是 Next-Key Lock 锁算法，因此可以避免幻读的产生，这与其他数据库系统（如：SQL Server）是不同的。 所以说 InnoDB 存储引擎的默认支持的隔离级别是REPEATABLE-READ 已经可以完全保证事务的隔离性要求，即达到了 SQL 标准的 SERIALIZABLE 隔离级别。 因为隔离级别越低，事务请求的锁就越少，所以大部分数据库系统的隔离级别都是 READ-COMMITED，但是 InnoDB 默认使用的 REPEATABLE-READ 并不会有任何性能损失。 InnoDB 存储引擎在分布式事务的情况下一般会用到 SERIALIZABLE 隔离级别。 3. 索引相关3.1 为什么要使用索引 通过创建唯一性索引，可以保证表中每一行数据的唯一性 可以大大加快数据的检索速度（大大减少检索的数据量），这是主要原因 帮助服务器避免排序和临时表 将随机 IO 变为顺序 IO 可以加速表和表之间的连接 3.2 索引是越多越好吗？ 当表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了维护速度 索引需要占物理空间 创建索引和维护索引需要时间 3.3 MySQL 的基本存储结构 每个数据页可以组成一个双向链表 每个数据页中的记录又可以组成一个单向链表 每个数据页都会为存储在其中的记录生产一个页目录，通过主键查找会比较快 以其他列（非主键）搜索的时候，只能从最小的开始遍历 3.4 索引是如何提高查询速度的 改变数据结构，将无序变为有序 找到 id 为 8 的记录： 很明显：没有索引，我们就需要遍历双向链表，现在通过 目录 就可以很快定位了。 3.5 使用索引的注意事项 在经常需要搜索的列上创建索引 在经常使用 WHERE 子句的列上面加索引 再经常需要排序的列上创建索引 对于中型到大型表索引都是非常有效的，但是特大型表的话维护开销会很大，不适合建索引 避免在 WHERE 子句中对字段施加函数，这回造成无法命中索引 在使用 InnoDB 的时候使用与业务无关的自增主键作为主键，即使用逻辑主键，而不要使用业务组件 将打算加索引的列设置为 NOT NULL，否则会导致引擎放弃使用索引而进行全表索引 删除长期未使用的索引，不用的索引的存在会造成不必要的性能损耗，在 sys 库的 chema_unused_indexes 中可查询（5.7 之后） 在使用 LiIMIT OFFSET 查询缓慢时，可以借助索引来提高性能 3.6 索引的主要数据结构 哈希索引：底层数据结构是哈希表，在绝大多数需求为单条记录查询的情况下可以使用 BTree 索引：底层是 B+ 树，MyISAM 和 InnoDB 底层实现会有不同 MyISAM B+ Tree 页节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按 B+ Tree 的搜索算法搜索索引，如果指定的 key 存在，取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为 非聚簇索引 InnoDB 其数据文件本身就是索引文件，与 MyISAM 相比，索引文件和数据文件是分离的，其表数据文件本身就是按照 B+ Tree 组织的一个索引结构 树的叶节点 data 域保存了完整的数据记录 这个索引的 key 是数据的主键，因此 InnoDB 表数据文件本身就是主索引，这被称为 聚簇索引 其他索引都作为辅助索引，辅助索引的 data 域存放是相应主键的值而不是地址 因此在设计表的时候，不建议使用过长的字段作为主键 3.7 覆盖索引 如果一个索引包含所有需要查询的字段的值，我们就称之为 覆盖索引 我们知道在 InnoDB 中，如果不是主键索引，叶子节点存储的是主键+列值，最终还是要 回表，也就是通过主键再索引一次，这样就会比较慢，覆盖索引就是把要查询出来的列和索引是对应的，不做回表操作。 比如： 创建了索引 username age 查询的时候 SELECT username, age FROM user WHERE username = &#39;JoJo&#39; AND age = 22 需要查询的数据的列都在，就不需要回表 3.8 索引查询原则 单行访问是很慢的，特别是在机械硬盘存储中（SSD 的随机 I/O 要快很多，不过这一点仍然成立），如果服务器从存储中读取一个数据块只是为了获取其中的一行，那么就浪费了很多工作，最好读取的块中能尽量包含更多需要的行。使用索引可以创建位置索引，用以提升效率。 按顺序访问范围数据是很快的 顺序 I/O 不需要多次磁盘寻道，所以比随机 I/O 要快很多（特别是对机械硬盘） 如果服务器能够按需要顺序读取数据，就不需要额外的排序操作，并且 GROUP BY 查询也能更快 索引覆盖查询是很快的 4. 左前缀原则MySQL 中的索引可以以一定的顺序引用多列，这种索引叫做联合索引。如 User 表的 name 和 city 创建了联合索引 (name, city)，而左前缀原则是指：如果查询的时候查询精确匹配条件的索引是左边连续一列或几列，则这几列都可以被用到： 1234SELECT * FROM User WHERE name = xx AND city = xx; // 可以命中索引SELECT * FROM User WHERE city = xx AND name = xx; // 可以命中索引SELECT * FROM User WHERE name = xx; // 可以命中索引SELECT * FROM User WHERE city = xx; // 不能命中索引 这里，第二中情况，如果条件都用上了，但是顺序不同，查询引擎会自动优化顺序 由于左前缀原则，在创建联合索引的时候，索引字段的顺序需要考虑字段值去重之后的个数，较多的放在前面，ORDER BY 也要遵循这个原则 5. 避免冗余索引冗余索引是指索引功能相同，能够命中那一个这个就一定能命中，那么就是冗余索引。 在大多数情况下，都尽量扩展已有的索引而不是创建新索引。 MySQL 5.7 后的版本，可以通过 sys 库中的 schema_redundant_indexes 表来查看冗余索引。 6. 添加索引主键索引（PRIMARY KEY） 1ALTER TABLE `table_name` ADD PRIMARY KEY (`column`) 唯一索引（UNIQUE） 1ALTER TABLE `table_name` ADD UNIQUE (`column`) 普通索引（INDEX） 1ALTER TABLE `table_name` ADD INDEX index_name (`column`) 全文索引（FULLTEXT） 1ALTER TABLE `table_name` ADD FULLTEXT (`column`) 多列索引 1ALTER TABLE `table_name` ADD INDEX index_name (`column1`, `column2`, `column3`) 7. MyISAM 与 InnoDB的区别MyISAM 是 MySQL 的默认数据库引擎（5.5 版本之前），由早期的 ISAM（Indexed Sequential Access Method，有索引的顺序访问方法）所改良。虽然性能极佳，而且提供了大量的特性，包括：全文索引、压缩、空间函数等，但 MyISAM 不支持事务和行级锁，而且最大的缺陷就是崩溃后无法安全恢复。 大多数时候我们使用的都是 InnoDB 存储引擎，但是在某些情况下使用 MyISAM 也是合适的，比如：读密集的情况下。 不要轻易相信 MyISAM 比 InnoDB 快之类的经验之谈，这个结论往往不是绝对的。在很多我们已知场景中，InnoDB 的速度都可以让 MyISAM望尘莫及，尤其是用到了聚簇索引，或者需要访问的数据都可以放入内存的应用。 —— 《MySQL 高性能》 一般情况下我们选择 InnoDB 都是没有问题的，但是某事情况下你并不在乎可扩展能力和并发能力，也不需要事务支持，也不在乎崩溃后的安全恢复问题的话，选择 MyISAM 也是一个不错的选择。但是一般情况下，我们都是需要考虑到这些问题的。 8. 乐观锁与悲观锁8.1 悲观锁总是做最坏的打算，每次拿数据都会认为别人会修改，所以每次拿数据的时候都会加上锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java 中 synchronized 和 ReentrantLock 等独占锁就是悲观锁思想的实现。 8.2 乐观锁总是做最好的打算，每次拿数据都会认为别人不会修改。但是在更新的时候会判断一下再此期间别人修改过这个数据没有，可以使用版本号机制和 CAS 算法实现。 乐观锁适用于多读的应用类型，可以提高吞吐量。 像数据库提供的类似于 write_condition 机制，其实都是提供的乐观锁。在 Java 中 java.util.concurrent.atomic 包下面的原子变量类就是使用了乐观锁的一种实现方式 CAS 实现的。 8.3 使用场景 乐观锁：写较少，多读 悲观锁：写较多 8.4 乐观锁的实现方式版本号机制 一般是在数据表中加入一个数据版本号 version 字段，表示数据被修改的次数，当数据被修改时 +1。当线程要更新数据值的时候，在读取数据的同时也会读取 version 值，在提交更新时，需要刚才读到的 version 值与当前数据库中的 version 值相同时才更新。否则就 rollback。 CAS 算法 即 compare and swap，是一种有名的无锁算法。无锁编程，即不使用锁的情况下实现多线程之间的变量同步，也就是在没有线程阻塞的情况下实现变量的同步，所以也叫非阻塞同步，CAS 算法涉及的三个操作数： 需要读写的内存值 V 进行比较的值 A 插入的新值 B 当且 V 的值等于 A 时，CAS 通过原子方式用新增 B 的值来更新 V 的值，否则不会执行任何操作（比较和替换是一个原子操作）。一般情况下是一个自选操作，即不断的重试。 8.5 乐观锁的缺点ABA 问题 如果一个变量 V 初次读取的值是 A，并且在准备赋值的时候检查到他还是 A，这段时间它的值可能被改为其他值，又被改回 A，这个时候 CAS 会认为它从来没有被修改过。 JDK 1.5 以后的 AtomicStampedReference 类就提供了此种能力，其中的 compareAndSet 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大 自旋 CAS 如果长时间不成功，会给 CPU 带来很大的开销。 如果JVM能支持处理器提供的 pause 指令那么效率会有一定的提升，pause 指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使 CPU 不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起 CPU 流水线被清空（CPU pipeline flush），从而提高 CPU 的执行效率。 只能保证一个共享变量的原子操作 CAS 只对单个共享变量有效，当操作涉及多个共享变量时 CAS 无效。但是从 JDK 1.5 开始，提供了 AtomicReference 类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行 CAS 操作.所以我们可以使用锁或者利用 AtomicReference 把多个共享变量合并成一个共享变量来操作。 9. 锁机制与 InnoDB 锁算法 MyISAM 采用表级锁（table-level locking） InnoDB 支持行级锁（row-level locking）和表级锁，默认为行级 表级锁：MySQL 中锁定粒度最大的一种锁，加锁快，不会出现死锁。并发最低，触发锁冲突的概率最高 行级锁：MySQL 中锁定粒度最小的一种锁，并发高，开销大，加锁满，会出现死锁 InnoDB 锁算法 Record Lock：单个行记录上的锁 Gap Lock：间隙锁，锁定一个范围，不包括记录本身 Next-key Lock：record + gap 锁定一个范围，包含记录本身 相关知识点 InnoDB 对于行的查询使用 next-key lock Next-locking keying 为了解决 Phantom Problem 幻读问题 当查询的索引含有唯一属性时，将 next-key lock 降级为 record key Gap 锁设计的目的是为了阻止多个事务将记录插入到同一范围内，而这会导致幻读问题的产生 有两种方式显式关闭 gap 锁：（除了外键约束和唯一性检查外，其余情况仅使用 record lock） 将事务隔离级别设置为 RC 将参数 innodb_locks_unsafe_for_binlog 设置为 1 10. 大表优化10.1 限定数据的范围务必禁止不带任何限制数据范围条件的查询语句。比如：我们当用户在查询订单历史的时候，我们可以控制在一个月的范围内； 10.2 读写分离经典的数据库拆分方案，主库负责写，从库负责读； 10.3 垂直分区根据数据库里面数据表的相关性进行拆分。 例如，用户表中既有用户的登录信息又有用户的基本信息，可以将用户表拆分成两个单独的表，甚至放到单独的库做分库。 简单来说垂直拆分是指数据表列的拆分，把一张列比较多的表拆分为多张表。 垂直拆分的优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。 垂直拆分的缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂； 10.4 水平分区保持数据表结构不变，通过某种策略存储数据分片。这样每一片数据分散到不同的表或者库中，达到了分布式的目的。 水平拆分可以支撑非常大的数据量。 水平拆分是指数据表行的拆分，表的行数超过200万行时，就会变慢，这时可以把一张的表的数据拆成多张表来存放。举个例子：我们可以将用户信息表拆分成多个用户信息表，这样就可以避免单一表数据量过大对性能造成影响。 水平拆分可以支持非常大的数据量。需要注意的一点是：分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以 水平拆分最好分库 。 水平拆分能够 支持非常大的数据量存储，应用端改造也少，但 分片事务难以解决 ，跨节点Join性能较差，逻辑复杂。《Java工程师修炼之道》的作者推荐 尽量不要对数据进行分片，因为拆分会带来逻辑、部署、运维的各种复杂度 ，一般的数据表在优化得当的情况下支撑千万以下的数据量是没有太大问题的。如果实在要分片，尽量选择客户端分片架构，这样可以减少一次和中间件的网络I/O。 下面补充一下数据库分片的两种常见方案： 客户端代理： 分片逻辑在应用端，封装在jar包中，通过修改或者封装 JDBC 层来实现。 当当网的 Sharding-JDBC 、阿里的 TDDL 是两种比较常用的实现。 中间件代理： 在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。 我们现在谈的 Mycat 、360 的 Atlas、网易的 DDB 等等都是这种架构的实现。 11. 一条 SQL 在 MySQL 中是如何执行的11.1 MySQL 基本架构简单来说 MySQL 主要分为 Server 层和存储引擎层： Server 层：主要包括连接器、查询缓存、分析器、优化器、执行器等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binglog 日志模块。 存储引擎： 主要负责数据的存储和读取，采用可以替换的插件式架构。 连接器：身份认证和权限相关 查询缓存：执行查询语句的时候，会先查询缓存（MySQL 8.0 后移除） 分析器：没有命中缓存，SQL 语句就会经过分析器，就是看你要干嘛，再看你语法对不对 优化器：按照 MySQL 认为最优方案去执行 执行器：执行语句，然后从存储引擎返回数据]]></content>
      <categories>
        <category>SQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>面试</tag>
        <tag>innodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出 MySQl（一）]]></title>
    <url>%2F2019%2F09%2F05%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA-MySQl%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1. 帮助的使用1.1 按层次看帮助12345678910111213141516171819202122mysql&gt; ? contentsYou asked for help about help category: "Contents"For more information, type 'help &lt;item&gt;', where &lt;item&gt; is one of the followingcategories: Account Management Administration Compound Statements Data Definition Data Manipulation Data Types Functions Functions and Modifiers for Use with GROUP BY Geographic Features Help Metadata Language Structure Plugins Procedures Storage Engines Table Maintenance Transactions User-Defined Functions Utility 对于列出的分类，可以进行看自己感兴趣的部分，比如： 123456789101112mysql&gt; ? data typesYou asked for help about help category: "Data Types"For more information, type 'help &lt;item&gt;', where &lt;item&gt; is one of the followingtopics: AUTO_INCREMENT BIGINT BINARY BIT BLOB BLOB DATA TYPE BOOLEAN...... 对于列出的具体数据类型，可以进一步查看过情况： 1234567mysql&gt; ? intName: 'INT'Description:INT[(M)] [UNSIGNED] [ZEROFILL]A normal-size integer. The signed range is -2147483648 to 2147483647.The unsigned range is 0 to 4294967295. 1.2 快速查阅帮助需要快速查阅某项语法时，可以使用关键字快速查阅： 12345678910111213141516171819202122mysql&gt; ? showName: 'SHOW'Description:SHOW has many forms that provide information about databases, tables,columns, or status information about the server. This section describesthose following:SHOW AUTHORSSHOW &#123;BINARY | MASTER&#125; LOGSSHOW BINLOG EVENTS [IN 'log_name'] [FROM pos] [LIMIT [offset,] row_count]SHOW CHARACTER SET [like_or_where]SHOW COLLATION [like_or_where]SHOW [FULL] COLUMNS FROM tbl_name [FROM db_name] [like_or_where]SHOW CONTRIBUTORSSHOW CREATE DATABASE db_nameSHOW CREATE EVENT event_nameSHOW CREATE FUNCTION func_nameSHOW CREATE PROCEDURE proc_nameSHOW CREATE TABLE tbl_nameSHOW CREATE TRIGGER trigger_nameSHOW CREATE VIEW view_name...... 我想知道 create table 的语法，可以命令如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859mysql&gt; ? create tableName: 'CREATE TABLE'Description:Syntax:CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name (create_definition,...) [table_options] [partition_options]CREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name [(create_definition,...)] [table_options] [partition_options] [IGNORE | REPLACE] [AS] query_expressionCREATE [TEMPORARY] TABLE [IF NOT EXISTS] tbl_name &#123; LIKE old_tbl_name | (LIKE old_tbl_name) &#125;create_definition: col_name column_definition | [CONSTRAINT [symbol]] PRIMARY KEY [index_type] (index_col_name,...) [index_option] ... | &#123;INDEX|KEY&#125; [index_name] [index_type] (index_col_name,...) [index_option] ... | [CONSTRAINT [symbol]] UNIQUE [INDEX|KEY] [index_name] [index_type] (index_col_name,...) [index_option] ... | &#123;FULLTEXT|SPATIAL&#125; [INDEX|KEY] [index_name] (index_col_name,...) [index_option] ... | [CONSTRAINT [symbol]] FOREIGN KEY [index_name] (index_col_name,...) reference_definition | CHECK (expr)column_definition: data_type [NOT NULL | NULL] [DEFAULT default_value] [AUTO_INCREMENT] [UNIQUE [KEY] | [PRIMARY] KEY] [COMMENT 'string'] [COLUMN_FORMAT &#123;FIXED|DYNAMIC|DEFAULT&#125;] [STORAGE &#123;DISK|MEMORY|DEFAULT&#125;] [reference_definition]data_type: BIT[(length)] | TINYINT[(length)] [UNSIGNED] [ZEROFILL] | SMALLINT[(length)] [UNSIGNED] [ZEROFILL] | MEDIUMINT[(length)] [UNSIGNED] [ZEROFILL] | INT[(length)] [UNSIGNED] [ZEROFILL] | INTEGER[(length)] [UNSIGNED] [ZEROFILL] | BIGINT[(length)] [UNSIGNED] [ZEROFILL] | REAL[(length,decimals)] [UNSIGNED] [ZEROFILL] | DOUBLE[(length,decimals)] [UNSIGNED] [ZEROFILL] | FLOAT[(length,decimals)] [UNSIGNED] [ZEROFILL] | DECIMAL[(length[,decimals])] [UNSIGNED] [ZEROFILL] | NUMERIC[(length[,decimals])] [UNSIGNED] [ZEROFILL] | DATE | TIME[(fsp)] | TIMESTAMP[(fsp)]...... 2. 表类型（存储引擎）的选择2.1 Mysql 存储引擎概述mysql 支持多种存储引擎，在处理不同类型的应用时，可以通过选择使用不同的存储引擎提高应用的效率，或者提供灵活的存储。 mysql 的存储引擎包括：MyISAM、InnoDB、BDB、MEMORY、EXAMPLE、NDB Cluster、ARCHIVE、CSV、BLACKHOLE、FEDERATED 等，其中 InnoDB 和 BDB 提供事务安全表，其他存储引擎都是非事务安全表。 2.2 各种存储引擎的特性 特点 MyISAM BDB Memory InnoDB Archive 存储限制 无 无 有 64TB 没有 事务安全 支持 支持 锁机制 表锁 页锁 表锁 行锁 行锁 B 树索引 支持 支持 支持 支持 哈希索引 支持 支持 全文索引 支持 集群索引 支持 数据缓存 支持 支持 索引缓存 支持 支持 支持 数据可压缩 支持 支持 空间使用 低 低 N/A 高 低 内存使用 低 低 中等 高 低 批量插入速度 高 高 高 低 非常高 支持外键 支持 最常用的两种引擎： MyISAM 是 MySQL 默认存储引擎（5.5 之前），每个 MyISAM 在磁盘上存储三个文件。文件名和表名相同，扩展名分别是 .frm（存储表定义）、.MYD（MyData，存储数据）、.MYI（MyIndex，存储索引）。数据和文件和索引文件可以放置在不同的目录，平均分布 io，获得更快的速度 InnoDb 是 MySQL 默认存储引擎（5.5 之后），InnoDB 存储引擎提供了具有提交、回滚和崩溃恢复的事务安全。但是对比 MyISAM 的存储引擎，InnoDB 写的效率会差一些并且会占用更多的磁盘空间以保留数据和索引 2.3 选择合适的存储引擎 MyISAM：在 Web、数据仓储和其他应用环境下 InnoDB：用于事务处理应用程序，具有众多特性，包括 ACID 事务支持 Memory：将所有数据保存在 RAM 中，在需要快速查找引用和其他类似数据的环境下，可以提供极快的访问 Merge：允许 MySQL DBA 或开发人员将一系列等同的 MyISAM 表以逻辑方式组合在一起，并作为一个对象引用他们。对于诸如数据仓储等 VLDB 环境十分适合]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>reading</tag>
        <tag>note</tag>
        <tag>深入浅出 MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 面试题（二）]]></title>
    <url>%2F2019%2F09%2F04%2FJVM-%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[垃圾回收算法、垃圾回收器、类加载机制… 1. 常见的垃圾回收算法 垃圾收集器：Serial、ParNew、Parallel Scavenge、CMS、G1 1.1 标记-清除 算法算法分为 标记 和 清除 两个阶段： 标记出所有需要回收的对象 标记完成后统一回收所有被标记的对象 这种算法会带来两个明显的问题：效率 和 空间 问题 1.2 复制算法为了解决效率问题，复制 收集算法出现了。它将内存分成大小相同的两块，每次使用其中的一块。当这块内存使用完了，就将存活的对象复制一份到另一块，然后把使用过的空间一次清理掉。这样每次内存回收都是对内存区间的一半进行回收。 1.3 标记-整理 算法根据老年代的特点设计的一种标记算法，标记过程任然与 标记-清除 算法一样，但是后续不是直接回收可回收对象，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。 1.4 分代收集算法当前虚拟机的垃圾收集都采用分代收集算法，这种算法没有什么新的思想，只是根据对象存活的周期的不同将内存分为几块。一般将 Java 堆分为新生代和老年代，这样我们就可以根据各个年代的特点选择合适的垃圾收集算法。 比如在新生代中，每次收集都会有大量对象死去，所以可以选择复制算法。 而老年代的对象存活概率是比较高的，也没有额外的空间对其进行分配担保，可以使用 标记-清除 或者 标记整理 算法。 2. 常见的垃圾回收器 如果说垃圾回收算法是内存回收的方法论，那么垃圾回收器就是内存回收的具体实现。 2.1 Serial 收集器 新生代采用复制算法，老年代采用标记-整理算法 Serial（串行）收集器是最基本、历史最悠久的垃圾收集器了。是一个单线程收集器，它单线程的意义不仅仅意味着它只会使用一条垃圾收集线程去完成垃圾收集工作，更重要的是它在进行垃圾收集工作的时候必须暂停其他所有的工作线程 Stop The World，直到它收集结束。 虚拟机的设计者当然知道 Stop The World 带来的不良用户体验，所以在后续的垃圾收集器设计中停顿时间在不断缩短（任然还有停顿，寻找最优秀的垃圾收集器的过程任然在继续）。 但是 Serial 也有优于其它垃圾收集器的优点： 简单而高效（与其它收集器的单线程相比） Serial 收集器对运行在 Client 模式下的虚拟机是个不错的选择。 2.2 ParNew 收集器 新生代采用复制算法，老年代采用标记-整理算法 ParNew 收集器其实就是 Serial 收集器的多线程版本，处理使用多线程进行垃圾收集以外，其余行为（控制参数、收集算法、回收策略）和 Serial 收集器完全一样。 它是许多运行在 Server 模式下的虚拟机的首要选择，除了 Serial 收集器外，只有它能与 CMS 收集器配合工作。 并行和并发： 并行（Paralled）：指多条垃圾收集线程并行工作，但此时用户线程仍处于等待状态 并发（Concurrent）：指用户线程和垃圾收集线程同时执行（可能是交替执行），用户程序仍在运行，垃圾收集器在另一个 CPU 上运行 2.3 Parallel Scavenge 收集器 新生代采用复制算法，老年代采用标记-整理算法 Parallel Scavenge 收集器类似于 ParNew 收集器，不同的是： 1234-XX:+UserParallelGC 使用 Parallel 收集器 + 老年代串行-XX:+UserParallelOldGC 使用 Parallel 收集器 + 老年代并行 Parallel Scavenge 收集器关注的点是吞吐量（高效利用 CPU）。CMS 等垃圾收集器的关注点是更多的用户线程的停顿时间（用户体验）。所谓吞吐量就是 CPU 用于运行用户代码的时间与 CPU 总消耗时间的比值。 Parallel Scavenge 收集器提供了很多参数供用户找到最合适的停顿时间或最大吞吐量，如果对于收集器运行不太了解的话，手工优化存在的话可以把内存优化交给虚拟机去完成也是一个不错的选择。 2.4 Serial Old 收集器Serial 收集器的老年代版本，他同样是一个单线程收集器，主要的用途： 在 JDK1.5 及以前的版本与 Parallel Scavenge 收集器搭配使用 作为 CMS 收集器的后备方案 2.5 Parallel Old 收集器Parallel Scavenge 收集器的老年代版本。使用多线程和 标记-整理 算法。 在注意吞吐量和 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。 2.6 CMS 收集器CMS（Concurrent Mark Sweep） 收集器是一种以获取最短时间停顿为目标的收集器。它非常注重用户体验。 CMS 收集器是 HotSpot 虚拟机第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程（基本上）同时工作。 从名字中的 Mark Sweep 这两个词可以看出，CMS 收集器是一种 标记-清除 算法的实现，它的运作过程相比于前面几种垃圾收集器更为复杂： 初始标记：暂停所有的其他线程，并记录下与 root 相连的对象，速度很快 并发标记：同时开启 GC 和用户线程，用一个闭包结构去记录可达对象。但在这个阶段结束，这个闭包结构并不能保证包含当前所有的可达对象。因为用户线程可能会不断的更新引用域，所以 GC 线程无法保证可达性分析的实时性。所以这个算法里会跟踪记录这些发生引用更新的地方 重新标记：重新标记阶段就是为了修正并发标记期间，因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短 并发清除：开启用户线程，同时 GC 线程开始对为标记的区域做清扫 优点： 并发收集 低停顿 缺点： 对 CPU 资源敏感 无法处理浮动垃圾 标记-清除 会导致收集结束时有大量空间碎片产生 2.7 G1 收集器G1（Garbage-First） 是一款面向服务器的垃圾收集器，主要针对匹配多颗处理器及大容量内存的机器，以极高概率满足 GC 停顿时间要求的同时，还具备高吞吐量性能特征。主要特点为： 并行与并发：G1 能充分利用 CPU、多核环境下的硬件优势，使用多个 CPU 来缩短 Stop the World 的停顿时间。部分其他收集器原本需要停顿 Java 线程执行的 GC 动作，G1 收集器仍然可以通过并发的方式让 Java 程序继续执行 分代收集：虽然 G1 可以不需要其他收集器配合就能独立管理整个 GC 堆，但是还是保留了分代的概念 空间整合：与 CMS 的 标记-清除 算法不同，G1 从整体来看是基于 标记-清除 算法的，但是从局部上来看是基于 复制 算法实现的 可预测的停顿：这是 G1 相对于 CMS 的另一个大优势，降低停顿时间是 G1 和 CMS 共同的关注点，但 G1 除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定一个长度为 M 毫秒的时间片段内 运作流程： 初始标记 并发标记 最终标记 筛选回收 G1 收集器在后台维护了一个优先列表，每次根据允许的收集时间，优先选择回收价值最大的 Region（这就是其名字的由来）。 这种使用 Region 划分内存空间以及有优先级的区域回收方式，保证了 G1 收集器在有限的时间内可以尽可能高的收集效率（把内存化整为零）。 3. 类文件结构 根据 Java 虚拟机规范，类文件由单个 ClassFile 结构组成： 123456789101112131415161718ClassFile &#123; u4 magic; //Class 文件的标志 u2 minor_version; //Class 的小版本号 u2 major_version; //Class 的大版本号 u2 constant_pool_count; //常量池的数量 cp_info constant_pool[constant_pool_count-1]; //常量池 u2 access_flags; //Class 的访问标记 u2 this_class; //当前类 u2 super_class; //父类 u2 interfaces_count; //接口 u2 interfaces[interfaces_count]; //一个类可以实现多个接口 u2 fields_count; //Class 文件的字段属性 field_info fields[fields_count]; //一个类会可以有个字段 u2 methods_count; //Class 文件的方法数量 method_info methods[methods_count]; //一个类可以有个多个方法 u2 attributes_count; //此类的属性表中的属性数 attribute_info attributes[attributes_count]; //属性表集合&#125; 魔数：确定这个文件是否为一个能够被虚拟机接收的 Class 文件 Class 文件版本：Class 文件的版本号，保证编译的正常执行 常量池：主要存放字面量和符号引用 访问标志：标志用于识别一些类或者接口层次的访问信息 这个 Class 是类还是接口 是否为 public 或者 abstract 类型 是否声明为 final 等等 当前类索引、父类索引：类索引用于确定这个类的全限定名，父类索引用于确定这个类的全限定名，由于 Java 语言的单继承，父类索引只有一个 除了 java.lang.Object 之外，所有的 java 类都有父类 除了 java.lang.Object 之外，所有的 java 类的父类索引都不为 0 接口索引集合：接口索引用来描述这个类实现了哪些接口，这些实现的接口将按 implements（如果这个类本身是接口的话则是 extends）后的接口顺序从左到右排列在接口索引集合中 字段表集合：描述接口或类中声明的变量，包括类级变量以及实例变量，不包括局部变量 方法表集合：类中的方法 属性表集合：在 Class 文件，字段表，方法表中都可以携带自己的属性 4. 类的加载过程 类加载过程：加载 -&gt; 连接 -&gt; 初始化；其中连接过程：验证 -&gt; 准备 -&gt; 解析 4.1 加载 通过全类名获取定义此类的二进制字节流 将字节流所代表的静态存储结构转换为方法区的运行时数据结构 在内存中生成一个代表该类的 Class 对象，作为方法区这些数据的访问入口 一个非数组类的加载阶段（获取二进制字节流）是可控性最强的阶段，这一步我们还可以自定义类加载器去控制字节流的获取方式（重写一个类加载器的 loadClass() 方法）。 数组类型不通过类加载器创建，它由 Java 虚拟机直接创建。 4.2 类加载器 JVM 中内置了三个重要的 ClassLoader，除了 BootstrapClassLoader 其他类加载器均由 Java 实现且全部继承自 java.lang.ClassLoader BootstrapClassLoader（启动类加载器）：最顶层的加载类，由 C++ 实现，负责加载 %JAVA_HOME%/lib 目录下的 jar 包和类或者被 -Xbootclasspath 参数指定的路径中的所有类 ExtensionClassLoader（扩展类加载器）：主要负责加载目录 %JRE_HOME%/lib/ext 目录下的 jar 包和类，或被 java.ext.dirs 系统变量所指指定的路径下的 jar 包 AppClassLoader（应用程序类加载器）：面向用户的加载器，负责加载当前应用 classpath 下的所有 jar 包和类 4.3 自定义类加载器 继承 java.lang.ClassLoader ，重写 findClass 方法 将 class 字节码数组转化为 Class 类的实例 调用 loadClass 方法 ClassLoader 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class MyClassLoader extends ClassLoader &#123; //指定路径 private String path ; public MyClassLoader(String classPath)&#123; path=classPath; &#125; /** * 重写findClass方法 * @param name 是我们这个类的全路径 * @return * @throws ClassNotFoundException */ @Override protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; Class log = null; // 获取该class文件字节码数组 byte[] classData = getData(); if (classData != null) &#123; // 将class的字节码数组转换成Class类的实例 log = defineClass(name, classData, 0, classData.length); &#125; return log; &#125; /** * 将class文件转化为字节码数组 * @return */ private byte[] getData() &#123; File file = new File(path); if (file.exists())&#123; FileInputStream in = null; ByteArrayOutputStream out = null; try &#123; in = new FileInputStream(file); out = new ByteArrayOutputStream(); byte[] buffer = new byte[1024]; int size = 0; while ((size = in.read(buffer)) != -1) &#123; out.write(buffer, 0, size); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; try &#123; in.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; return out.toByteArray(); &#125;else&#123; return null; &#125; &#125;&#125; 实例 123456public class Log &#123; public static void main(String[] args) &#123; System.out.println("load Log class successfully"); &#125;&#125; Shell 1$ javac Log.java Main 1234567891011121314151617181920212223public class ClassLoaderMain &#123; public static void main(String[] args) throws Exception &#123; //这个类class的路径 String classPath = "/code/src/com/hachi/classloaderdemo/Log.class"; MyClassLoader myClassLoader = new MyClassLoader(classPath); //类的全称 String packageNamePath = "com.hachi.classloaderdemo.Log"; //加载Log这个class文件 Class&lt;?&gt; Log = myClassLoader.loadClass(packageNamePath); System.out.println("类加载器是:" + Log.getClassLoader()); //利用反射获取main方法 Method method = Log.getDeclaredMethod("main", String[].class); Object object = Log.newInstance(); String[] arg = &#123;"ad"&#125;; method.invoke(object, (Object) arg); &#125;&#125; OutPut 1234类加载器是:sun.misc.Launcher$AppClassLoader@18b4aac2load Log class successfullyProcess finished with exit code 0 5. 双亲委派模型5.1 介绍每一个类都有一个对应它的类加载器。系统中的 ClassLoader 在协同工作的时候会默认使用 双亲委派模型。即在类加载的时候，系统会首先判断当前类是否被加载过。已经被加载的类会直接返回，否则才会尝试加载。 加载的时候，首先会把该请求委派该父类加载器的 loadClass() 处理，因此所有的请求最终都应该传送到顶层的启动类加载器 BootstrapClassLoader 中。当父类加载器无法处理时，才由自己处理。当父类加载器为 null 时，会使用启动类加载器 BootstrapClassLoader 作为父类加载器。 每个类加载都有一个父类加载器： 1234567public class ClassLoaderDemo &#123; public static void main(String[] args) &#123; System.out.println("ClassLodarDemo's ClassLoader is " + ClassLoaderDemo.class.getClassLoader()); System.out.println("The Parent of ClassLodarDemo's ClassLoader is " + ClassLoaderDemo.class.getClassLoader().getParent()); System.out.println("The GrandParent of ClassLodarDemo's ClassLoader is " + ClassLoaderDemo.class.getClassLoader().getParent().getParent()); &#125;&#125; Output： 123ClassLodarDemo&apos;s ClassLoader is sun.misc.Launcher$AppClassLoader@18b4aac2The Parent of ClassLodarDemo&apos;s ClassLoader is sun.misc.Launcher$ExtClassLoader@1b6d3586The GrandParent of ClassLodarDemo&apos;s ClassLoader is null AppClassLoader 的父类加载器为 ExtClassLoader，ExtClassLoader 的父类加载器为 null，null 并不代表 ExtClassLoader 没有父类加载器，而是 BootstrapClassLoader。 这里的 双亲类加载器 更多的是表达 父母这一辈 的人，另外类加载器之间的 父子 关系也不是通过继承来实现的，而是通过 优先级 来决定的： The Java platform uses a delegation model for loading classes. The basic idea is that every class loader has a “parent” class loader. When loading a class, a class loader first “delegates” the search for the class to its parent class loader before attempting to find the class itself. 5.2 双亲委派模型实现源码分析双亲委派模型的实现代码非常简单，逻辑非常清晰，都集中在 java.lang.ClassLoader 中的 loadClass() 中： 123456789101112131415161718192021222324252627282930313233343536private final ClassLoader parent; protected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException &#123; synchronized (getClassLoadingLock(name)) &#123; // 首先，检查请求的类是否已经被加载过 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; if (parent != null) &#123;//父加载器不为空，调用父加载器loadClass()方法处理 c = parent.loadClass(name, false); &#125; else &#123;//父加载器为空，使用启动类加载器 BootstrapClassLoader 加载 c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; //抛出异常说明父类加载器无法完成加载请求 &#125; if (c == null) &#123; long t1 = System.nanoTime(); //自己尝试加载 c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; &#125; 5.3 双亲委派模型的好处双亲委派模型保证了 Java 程序的稳定运行，可以避免类的重复加载（JVM 区分不同类的方式不仅仅根据类名，相同类文件被不同的类加载器加载产生的是两个不同的类），也保证了 Java 的核心 API 不被篡改，而是每个类加载器加载自己的话就会出现一个问题，比如我们编写一个 java.lang.Object 类的话，那么程序运行的时候，系统就会出现多个不同的 Object 类。 5.4 如果不想用双亲委派模型怎么办自定义类加载器，重载 loadClass()]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM 面试题（一）]]></title>
    <url>%2F2019%2F08%2F30%2FJVM-%E9%9D%A2%E8%AF%95%E9%A2%98%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[JVM 内存模型、Java 对象的创建过程、对象的访问定位、判断对象，常量，类是否还有用… 1. Java 内存模型Java 虚拟机在执行 Java 程序的过程中会把它所管理的内存区域划分为若干个不同的数据区域： 1.1 程序计数器程序计数器是一块较小的内存空间，可以看作是当前线程所执行的行号指示器。 字节码解释器工作时通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等功能都需要依赖这个计数器来完成。 另外，为了线程切换后能恢复到正确的执行位置，每条线程都需要一个独立的程序计数器，各线程之间计数器互补影响，独立存储，我们称这类内存区域为 线程私有 的内存。 程序计数器的主要作用 字节码通过改变程序计数器来依次读取指令来实现代码的流程控制 在多线程情况下，用来记录当前线程的执行位置 注意： 程序计数器是唯一一个不会出现 OOM 的内存区域，它的生命周期随着线程的创建而创建，随着线程的结束而死亡。 1.2 虚拟机栈与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期和线程相同，描述的是 Java 方法执行的内存模型，每次方法调用的数据都是通过栈传递的。 Java 内存可以粗糙的分为 堆（Heap） 和 栈（Stack），其中栈就是虚拟机栈，或者说是虚拟机中的局部变量表部分。（实际上，Java 虚拟机栈是由一个一个栈帧组成，而每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息等） 局部变量表主要存放了编译器可知的各种数据类型（boolean、byte、char、short、int、float、long、double）、对象引用 Java 虚拟机会出现两种异常： StackOverFlowError： 若 Java 虚拟机栈的内存不允许动态扩展，当线程请求栈的深度大于虚拟机的最大深度时会出现 OutOfMemoryError：若 Java 虚拟机栈允许动态扩展，且线程请求栈时内存用完了，就会出现 如何调用方法？ Java 栈可类比为数据结构中的栈，每次函数调用都会有一个栈帧被压入 Java 栈，每一个函数调用结束后，都会有一个栈帧被弹出。 Java 方法有两种返回方式：return 和异常，不论哪种，栈帧都会被弹出。 1.3 本地方法栈和虚拟机所发挥的作用非常相似，区别是：虚拟机栈为虚拟机执行 Java 方法（也就是字节码）服务，而本地方法栈作为虚拟机使用到的 Native 方法。在 HotSpot 虚拟机和 Java 虚拟机栈合二为一。 本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量，操作数栈、动态链接、出口信息。 方法执行完毕后相应的栈帧也会出栈并释放内存空间，也会出现 SOF 和 OOM 两种异常。 1.4 堆Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。 Java 堆是垃圾收集器管理的主要区域，因此也被称为 GC 堆（Garbage Collected Heap）。 从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以 Java 堆还可以细分为：新生代和老年代；再细致一点就是 Eden、From Survivor、To Survivor 空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存。 上图所示的 eden 区，s0，s1 区都属于新生代，tentired 属于老年代。大部分情况，对象都会首先在 Eden 区域分配，在一次新生代垃圾回收后，如果对象还存活，则会进入 s0 或者 s1，并且对象的年龄还会 +1（Eden 区 -&gt; Survivor 区后对象的初始年龄变为 1），当它的年龄增加到一定程度（默认为 15岁），机会被晋升到老年代中。对象晋升到老年代的年龄阈值，可以通过参数：-XX:MaxTenuringThreshold 来设置。 1.5 方法区方法区与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它还有一个别名叫 No-Heap 1.5.1 方法区和永久代的关系 方法区也被称为永久代 方法区和永久代的关系类似于 Java 中接口和类的关系，类实现了接口，而永久代就是 HotSpot 虚拟机对虚拟机规范中方法区的一种实现。 也就是说，永久代是 HosSpot 的概念，方法区是Java虚拟机规范中的定义，是一种规范，而永久代是一种实现，一个是标准一个是实现，其他的虚拟机实现并没有永久带这一说法。 1.5.2 常用参数 -XX:MetaspaceSize=n：设置 MetaSpace 的初始大小（最小大小） -XX:MaxMetaspaceSize=n：MetaSpace 的最大大小 1.5.3 为什么要将永久代（PermGen）替换为元空间（MetaSpace）呢？整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间是直接使用内存，受本机可用内存的限制，并且永远不会得到 OOM 异常。 这只是其中一个原因。 1.6 运行时常量运行时常量是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外、还有常量池信息（用于存放编译器生成的各种字面量和符号引用） 既然运行时常量池也是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OOM 异常。 JDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。 1.7 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。 JDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。 本机直接内存的分配不会收到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。 2. Java 对象的创建过程2.1 类加载检查虚拟机遇到一条 new 命令，首先去检查这个指令参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已经被加载过、解析和初始化过。如果没有，就必须执行相应的类加载过程。 2.2 分配内存在类加载检查通过后，接下来虚拟机将为新生对象分配内存，对象所需的内存大小在类加载完成后便可确定，为对象分配空间的任务等同于把一块确定大小的内存从 Java 堆中划分出来。 分配方式有 指针碰撞 和 空闲列表 两种，选择哪种分配方式由 Java 堆是否规定决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 2.2.1 内存分配的两种方式选择以上两种方式的哪一种，取决于 Java 堆内存是否规整。而 Java 堆内存的规整取决于 GC 收集器的算法是 标记-清除，还是 标记-整理，值得注意的是，复制算法内存也算是规整的 2.2.2 分配内存并发问题在创建对象的时候有一个很重要的问题，就是线程安全，因为在实际开发过程中，创建对象是很频繁的事情，作为虚拟机来说，必须要保证线程是安全的，通常来讲，虚拟机采用两种方式来保证线程安全： CAS + 失败重试：CAS 是乐观锁的一种实现方式。所谓乐观锁就是，每次不加锁而是假设没有冲突去完成某项操作，如果因为冲突失败就重试，直到成功为止。虚拟机采用 CAS 配上失败重试的方式保证更新操作的原子性 TLAB：为每一个线程预先在 Eden 区分配一块内存，JVM 在给线程中的对象分配内存时，首先在 TLAB 分配，当对象大于 TLAB 中剩余内存或 TLAB 的内存已经用尽时，再采用上述的 CAS 进行分配 2.3 初始化零值内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），这一步操作保证了对象的实例字段在 Java 代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 2.4 设置对象头初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是那个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。这些信息存放在对象头中。另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 2.5 执行 init 方法在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已近产生了，但从 Java 程序的视角来看，对象创建才刚开始，&lt;init&gt; 方法还没有执行，所有的字段都还为零。所以一般来说，执行 new 指令之后会接着执行 &lt;init&gt; 方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。 3. 对象的访问定位方式 建立对象就是为了使用对象，我们 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有 3.1 句柄使用句柄的话，在 Java 堆中将会划分出一块内存来作为句柄池，reference 中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自的具体地址信息。 3.2 直接指针使用了 直接指针访问，在 Java 堆对象的布局中就必须考虑如何防止访问类型数据的相关信息，而 reference 中存储的直接就是对象的地址 这两种对象的访问各有优势： 使用句柄来访问的最大好处是 reference 中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而 reference 本身不需要修改。 使用直接指针的最大好处是速度块，节省了一次指针定位的时间开销。 4. Minor GC 和 Full GC 的区别大多数情况下，对象在新生代中 eden 区分配。当 eden 区没有足够空间进行分配时，虚拟机将发起一次 Minor GC。 新生代 GC（Minor GC）：只发生在新生代的垃圾收集动作，Minor GC 非常频繁，回收速度一般也比较快 老年代 GC（Major GC/Full GC）：只发生在老年代的 GC，出现了 Major GC 经常会伴随至少一次的 Full GC（并非绝对），Major GC 的速度一般会比 Minor GC 的速度慢 10 倍以上。 5. 判断对象是否死亡 堆中几乎放着所有的对象实例，对堆垃圾回收前的第一步就是要判断那些对象已经死亡（即不能再被任何途径使用的对象） 5.1 引用计数法给对象中添加一个引用计数器，每当有一个地方引用它，计数器就 +1，当引用失败就 -1，任何时候计数器为 0 的对象就是不可能再被使用的。 5.2 可达性分析算法这个算法的基本思想就是通过一系列的称为 GC Roots 的对象作为起点，从这些节点开始向下搜索，节点所走过的路径称为引用链，当一个对象到 GC Roots 没有任何引用链相连的话，就证明此对象是不可用的。 6. 对象的引用 无论是通过引用计数法判断对象引用数量，还是通过可达性分析法判断对象的引用链是否可达，判断对象的存活都与 引用 有关。 JDK 1.2 之前，Java 中引用的定义很传统：如果 reference 类型的数据存储的数值代表的是另一块内存的起始地址，就称这块内存代表一个 引用 JDK 1.2 之后，Java 对引用的概念进行了扩充，将引用分为 强引用、软引用、弱引用、虚引用 四种（引用强度逐渐减弱） 6.1 强引用（Strong Reference）以前我们使用的大部分引用实际上都是强引用，这是使用最普遍的引用。 如果一个独享具有强引用，那就类似于必不可少的生活永平，垃圾回收器绝对不会回收它。当内存空间不足时，Java 虚拟机宁愿 OOM，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足问题。 6.2 软引用（Soft Reference）如果一个对象只有软引用，那就类似于可有可无的生活用品。如果内存的空间足够，垃圾回收器就不会回收它，如果内存空间不足了，就会回收这些对象的内存。只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（Reference Queue）联合使用，如果软引用所引用的对象被垃圾回收，Java 虚拟机就会把这个软引用加入到与之关联的引用队列中。 6.3 弱引用（Weak Reference）如果一个对象只具有弱引用，那就类似于可有可无的生活用品。 弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间是否足够，都会回收它的内存。不过，由于垃圾回收器是一个优先级很低的线程，因此不一定会很快发现那些只具有弱引用的对象。 弱引用也可以和引用队列联合使用。 6.4 虚引用（Phantom Reference）虚引用 顾名思义，就是形同虚设，与其他几种引用不同，虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收。 虚引用主要用来跟踪对象被垃圾回收的活动。 虚引用与软引用和弱引用的一个区别在于： 虚引用必须和引用队列（ReferenceQueue）联合使用。当垃 圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存之前，把这个虚引用加入到与之关联的引用队列中。程序可以通过判断引用队列中是 否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。程序如果发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。 特别注意，在程序设计中一般很少使用弱引用与虚引用，使用软引用的情况较多，这是因为软引用可以加速JVM对垃圾内存的回收速度，可以维护系统的运行安全，防止内存溢出（OutOfMemory）等问题的产生。 7. 判断常量是否废弃 运行时常量池主要回收的是废弃的常量，那么如何判断常量的废弃呢？ 假如在常量池中存在字符串 &quot;abc&quot;，如果当前没有任何 String 对象引用该字符串常量的话，就说明常量 &quot;abc&quot; 就是废弃常量，如果这时候发生内存回收的话而且有必要的话，&quot;abc&quot; 就会被系统清理出常量池。 8. 判断类是否无用 无用的类是由方法区回收 判断一个常量是否是 废弃变量 比较简单，但判断一个类是否是 无用的类 的条件比较苛刻： 该类所有的实例都已经被回收，也就是说 Java 堆中不存在该类的任何实例 加载该类的 ClassLoader 已经被回收 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过发射访问该类的方法 虚拟机可以对满足上述 3 个条件的无用类进行回收，并不是一定。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>面试</tag>
        <tag>jvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim 实用技巧（二）- 普通模式]]></title>
    <url>%2F2019%2F08%2F30%2Fvim-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[普通模式是 vim 的自然放松状态，其他文本编辑器大部分时间都处于类似于 vim 插入模式的状态中。普通模式命令的强大，很大程度上源于他可以把操作符与动作结合在一起。 技巧7： 停顿时请移开画笔 对于不习惯 vim 的人来说，普通模式看上去是一种奇怪的缺省状态，但有经验的 vim 用户却很难想象还有其他任何方式。 你估计画家会花费多少时间用画笔在画布上作画？毫无疑问，这因人而异，但是，如果这占了画家全部工作时间的一半还要多的话，我会觉得非常诧异。 想一下除了画画外，画家还要做哪些事情。他们要研究主题，调整光线，把颜料混合成新的色彩。而且，在把颜料往画布上画时，谁说他们必须要用画笔？画家也许会换用刻刀来实现不同的质地，或是用棉签来对已经画好的地方进行润色。 画家在休息时不会把画笔放在画布上。对 vim 而言也是这样，普通模式就是 vim的自然放松状态，其名字已经寓示了这一点。 就像画家只花一小部分时间涂色一样，程序员也只花一小部分时间编写代码。绝大多数时间用来思考、阅读，以及在代码中穿梭浏览。而且，当确实需要做修改时，谁说一定要切换到插入模式才行？我们可以重新调整已有代码的格式，复制它们，移动其位置，或是删除它们。在普通模式中，我们有众多的工具可以利用。 技巧8： 把撤销单元切成块 在其他编辑器中，输入一些词后使用撤销命令，可能会撤销最后输入的词或字符。然而在 vim 中，我们可以自己控制撤销的粒度。 u 键会触发撤销命令，它会撤销最新的修改。一次修改可以是改变文档内文本的任意操作，其中包括在普通模式、可视模式以及命令行模式中所触发的命令，而且一次修改也包括了在插入模式中输入（或删除）的文本，因此我们可以说，i{insert some text}&lt;Esc&gt; 是一次修改。 在 vim 中，我们可以自己控制撤销命令的粒度。从进入插入模式开始，直到返回普通模式，在此期间输入或删除的任何内容都被视为一次修改。因此我们只需要控制好对 &lt;Esc&gt; 键的使用，就可以使撤销命令作用于单词、句子、段落。 在句尾停顿的时候，就可以使用 &lt;Esc&gt; 退出插入模式了。在准备好继续写的时候，按 A 命令就可以回到原来的地方继续写作。 当处于行尾的时候，另起一行的最快方式是按 &lt;CR&gt;，不过更好的方式是 &lt;Esc&gt;o，这样会以一行来控制撤销的粒度。 在插入模式中移动光标会重置修改状态 当使用了 &lt;Up&gt;、Down、Left、Right 这些光标键，将会产生一个新的撤销块，会对 u、. 等命令产生影响。 技巧9： 构造可重复的修改 vim 对重复操作进行了优化，要利用这一点，我们必须考虑该如何构造修改。 测试文本 我们要删除最后一个单词 nigh，假设光标已经在最后一个字符 h 上了 1The end is nigh 反向删除 db 命令从光标起始位置到单词开头的位置 x 删除 db 命令遗留下来的字符 h 这个操作的 vim 高尔夫得分是 3 分 正向删除 先使用 b 命令把光标移动到单词的开头 dw 命令删除一个单词 这个操作的 vim 高尔夫得分是 3 分 删除整个单词 我们可以使用更为精确的 aw 文本对象，而不是动作命令（详见：:h aw） 可以把 daw 解读为 delete a word 方便记忆 在技巧 51 和技巧 52 中会介绍更多关于文本对象的细节 3 分 哪种方法最具重复性？ 我们尝试了 3 种方法来删除一个词：dbx、bdw、daw。每种情况下的 vim 高尔夫得分都是 3 分。 很明显，daw 只有一个操作，最适合和 . 配合使用，而且 daw 命令还会删除一个空格。 技巧10： 用次数做简单的算术运算 大多数普通模式命令可以在执行时指定次数，我们可以利用这个功能来做简单的算术运算。 很多普通命令都可以带一个次数前缀，这样 vim 就会尝试把该命令执行指定的次数，而不是只执行一次（详见：:h count） &lt;C-a&gt;： 对数字执行加 &lt;C-x&gt;： 对数字执行减 在不带执行次数的时候，他们会逐个加减，但是如果加上前缀，就可以让他们加减任意整数，比如将光标移动到数字 5 上，执行 10&lt;C-a&gt; 就会把它变成 15。 如果光标不在数字上，&lt;C-a&gt; 命令 会把当前光标之上或之后的数值加上 [count]（详见：:h ctrl-a）。因此如果光标不在数字上，会在当前行正向查找一个数字，如果找到了，就直接跳转到那里。 12.blog, .news &#123; background-image: url(/sprite.png); &#125;.blog &#123; background-position: 0px 0px &#125; 我们想最后实现： 123.blog, .news &#123; background-image: url(/sprite.png); &#125;.blog &#123; background-position: 0px 0px &#125;.news &#123; background-position: -180px 0px &#125; 我们先使用 yyp 复制此行，然后使用 cw 修改第一个单词，然后再处理数值： 一种做法是用 f0 调到此数字，然后进入插入模式手动修改它的值，即 i-18&lt;Esc&gt; 更好的方法是 180&lt;c-x&gt; 在本例中，我们只复制了一行并做出改动。但是，假设你要复制 10 份，并对后续数字依次减 180。如果要切换到插入模式去修改每个数字，我们每次都得输入不同内容（-180，然后-360，以此类推）。但是如果用 180 命令的话，对后续行也可以采用相同的操作过程。我们甚至还可以把这组按键操作录制成一个宏（详见第 11章），然后根据需要执行多次。 数字的格式 007 的后面是什么？ 正确的答案是 010，像在某些编程语言中的约定一样，vim 把以 0 开头的数字解释为 8 进制，而不是 10 进制。如果你经常使用 8 进制，vim 的缺省行为或许会适合你，如果不是这样，在 vimrc 中，设置： 1set nrformats= 这样 vim 会把所有的数字都当作 10 进制，不管他们是不是以 0 开头的。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>reading</tag>
        <tag>note</tag>
        <tag>vim 实用技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim 实用技巧（一）- Vim 解决问题的方式]]></title>
    <url>%2F2019%2F08%2F29%2Fvim-%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本质上讲，我们的工作是重复性的。不论是在几个不同的地方做相同的小改动，还是在文档的相似结构间移动，我们都会重复很多操作。凡是可以简化重复性操作的方式，都会成倍地节省我们的时间。 技巧1： 结识 . 命令 . 命令可以让我们重复上次的修改 测试文本 12345$ cat test.txtLine oneLine twoLine threeLine four x 命令会删除光标下的字符，在这种情况下使用 . 命令 “重复上次修改” 时，就会让 Vim 删除光标下的字符： &gt;G 命令会增加从当前行到文档末尾处的缩进层级，如果我们在使用了此命令之后使用了 . 命令，那么 “重复上次修改” 会让 vim 增加从当前行到文档末尾的缩进层级： x， &gt; 命令都是在普通模式中执行的命令，不过，我们每次进入插入模式时，也会形成一次修改。从进入插入模式的那一刻起，直至返回普通模式，vim 会记录每一个按键操作。做出这样一个修改后再用 . 命令，它会重新执行所有这些按键的操作（参见技巧 8）。 . 是一个微型的宏 技巧2： 不要自我重复 对于在行尾添加内容这样常见的操作，如添加 ;，vim 专门提供了一个专门的命令，可以把两步操作合成一步 测试文件 123var foo = 1var bar = 'a'var foobar = foo + bar 在每一行的末尾添加分号 ; 普通方法 使用 $ 到行尾 使用 a 在光标之后插入 添加 ; Esc 退出插入模式 j $ . ： 此时 . 代替了三个键（a ; Esc） 减少不相关的移动 使用 A 代替 $ 和 a 一键移动，另一键操作，真是太完美了！请留意这种应用模式，因为我们即将在更多的例子中看到它的身影。 虽然这一模式对这个简短的例子来说很好用，但它不是万能的。试想一下，如果我们不得不给连续 50 行添加分号，即便每个修改输一次 j. ，看起来也是一项很繁重的工作。跳到技巧 30 可以看到另外一种解决方法。 技巧3： 以退为进 我们可以用一种常用的 vim 操作习惯在一个字符前后各添加一个空格。乍一看，这种方法比较古怪，不过好处是可以重复 测试文本 123var foo = "method("+argument1+","+argument2+")";// 需要改变为：var foo = "method(" + argument1 + "," + argument2 + ")"; 使移动可重复 f{char} 命令让 vim 查找下一处指定字符出现的位置，如果找到了，就直接把光标移动到那里（详细可见 :h f）。因此当我们输入 f+ 时，光标会直接移到下一个出现 + 的位置。我们将会在技巧 49 里学到更多关于 f{char} 命令的知识。 完成第一处修改后，可以直接重复按 f+ 去找下一个加号，不过 ; 命令会重复查找上次 f 命令所查找的字符，因此我们不用连续输入 4 次 f+，而是只用输入一次，剩下的直接输入 ; 就好了。 s 命令把两个操作合为一个：它先删除光标下的字符，然后进入插入模式。在删除 + 后，我们先输入 + ，然后退出插入模式。 先退一步，然后前进三步，看起来可能不够直接。但是这样做的最大的好处是：我们可以使用 . 命令重复这一修改操作。我们需要做的只是把光标移动到下一个 + 处，使用 . 命令重复这一操作即可。 技巧4： 执行、重复、返回 在面对重复性工作时，我们需要移动动作和修改动作都能够重复，这样就可以达到一个最佳的编辑模式。这样 vim 就可以记住我们的操作。本节是介绍这些可重复操作，并学习如何回退。 . 可以重复上次修改 @: 可以用来重复任意 ex 命令（在技巧 31 中讨论） &amp; 可以重复上一次的 :substitute 命令（参见技巧 92） 当 vim 让一个操作或移动可以很方便的重复时，它总是会提供某种方式，让我们在不小心做过头时能够回退，表 1-1 总结了 vim 中可重复执行的命令，以及相应的回退方式。 技巧5： 查找并手动替换 vim 提供了一个 :substitute 命令专门用于查找替换功能，不过用上面的技术，我们也可以手动修改第一个出现的地方，然后再一个一个的替换其他匹配项。 测试文本 在下面这段文本中，每一行都出现了单词 content 123...We&apos;re waiting for content before the site can go live......If you are content with this, let&apos;s go ahead with it......We&apos;ll launch as soon as we have the content... 假设我们想用单词 copy 来替代 content，其实很简单，只需要： 1:%s/content/copy/g 但是我们并不想所有的 content 都被替换成 copy，因为有的地方可能会出现语义错误。需要时刻留神，对每个地方都要问 这里需要修改吗？，subtitute 也能胜任这个工作（技巧 89），不过我们这里有另一种方法. 偷懒的办法： 无需输入就可以进行查找 * 命令可以查找当前光标下的单词（详见： :h *）。我们可以先直接查找 content 单词： 1/content 或者，简单的把光标放在这个单词上，然后按 * 键： 刚开始，把光标移动到 content 上，然后使用 * 命令，这样会产生两个结果： 光标会跳到下一个匹配项上 所有出现这个词的地方都会被高亮，如果没有高亮，需要设置 :set hls，详情可见技巧 80 执行过一次查找的命令之后，我们只需要按 n 就可以跳到下一个匹配项了，按 N 就是返回到上一次搜索的地方。 使修改可重复 当光标位于 content 的开头时，我们就可以开始修改了：需要删除这个单词，然后输入代替的词。cw 命令将这两步合成了一步。 因此只需要 cw copy Esc 就修改完成了，按 n 到下一个匹配处，考虑是否需要修改，需要修改的话就按 . 重复上一次修改。 技巧6： 结识 . 范式 到目前为止的三个简单的编辑任务，我们都使用了 . 命令解决了问题。 回顾前面三个 . 命令编辑任务 在技巧 2 中，我们想在一系列行的结尾添加分号。我们先用 A;&lt;Esc&gt;修改了第一行，做完这步准备后，就可以使用 . 命令对后续行重复此修改。我们使用了j命令在行间移动，要完成剩余的修改，只需简单地按足够多次 j.就可以了。 在技巧 3 中，我们想为每个+ 号的前后各添加一个空格。我们先用 f+ 命令跳到目标字符上，然后用 s 命令把一个字符替换成 3 个，做完这步准备后，我们就可以按若干次 ;. 完成此任务。 在技巧 5 中，我们想把每处出现单词 content 的地方都替换成 copy。我们使用 * 命令来查找目标单词，然后用 cw 命令修改第一处地方。做完这步准备后，就可以用 n 键跳到下一匹配项，然后用 . 键做相同的修改。要完成这项任务，只需简单地按足够多次 n. 就行了。 理想模式： 用一键移动，另一键执行 这些例子的共同点就是：用一键移动，另一键执行，为了方便起见，我们把它称作 . 范式。]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>reading</tag>
        <tag>note</tag>
        <tag>vim 实用技巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vim 使用手册]]></title>
    <url>%2F2019%2F08%2F28%2Fvim-%E4%BD%BF%E7%94%A8%E6%89%8B%E5%86%8C%2F</url>
    <content type="text"><![CDATA[vim 是从 vi 发展出来的一个文本编辑器。代码补全、编译及错误跳转等方便编程的功能特别丰富，在程序员中被广泛使用。 vim 的常用命令以及配置。 1. 正常模式1.1 光标移动 h、j、k、l： 分别对应着 ←、↓、↑、→ 字符移动 space ：向右移动一个字符 nspace：向右移动 n 个字符 backspace ：向左移动一个字符 nbackspace：向左移动 n 个字符 fo： 在当前行内下一个出现字母 o 的地方 Fo： 当前行内，上一个出现字母 o 的地方 ;： 配合 f、F、t、T 使用，到下一个搜索的地方 ,： 到上一个搜索的地方 单词移动 w： 向右移动一个词，定位在词首 W： 向右移动一个长单词，定位在词首 b： 向左移动一个词，定位在词首 B： 向左移动一个长单词，定位在词首 e：向右移动一个词，并且光标定位在词尾 E： 向右移动一个长单词，定位在词尾 行移动 ctrl+p： 向上移动一行 ctrl+n： 向下移动一行 Enter： 向下移动一行 nEnter： 向下移动 n 行 n+： 向下移动 n 行 n-： 向上移动 n 行 0 | ^ | &lt;Home&gt;： 到行首 $ | &lt;End&gt;： 到行尾 gg： 到第一行 G： 到最后一行 nG： 移动到第 n 行行首 H： 当前屏幕的顶行 M： 当前屏幕的中间行 L： 当前屏幕的底行 ctrl+o： 跳转到上次的地方 句、段移动 (： 到句首 )： 下一句的句首 {： 到段首 }： 到段尾 屏幕移动 ctrl+y： 向上滚屏 ctrl+e： 向下滚屏 ctrl+u： 向上滚动半屏 ctrl+d： 向下滚动半屏 ctrl+b： 向上滚动整屏 ctrl+f： 向下滚动整屏 zt： 将当前行变为屏幕第一行 zz： 将当前行变为中间行 zb： 将当前行变为尾行 1.2 操作编辑删除 x： 删除光标所在的一个字符 nx： 删除包括光标所在的字符的共 n 个字符 X： 删除光标之前的一个字符 nX： 删除光标之前的 n 个字符 D： 删除光标所在的字符至行尾 dw： 删除一个单词（在光标之后） ndw： 删除 n 个单词 d(： 删除至行首 d$： 删除至行尾 dd： 删除当前行 ndd： 删除包括当前行的 n 行 d(： 从光标位置删除到上一行行首 d)： 从光标位置删除到下一行行首 d{： 从光标位置删除到上一段开始所有字符 d}： 从光标位置删除到下一段开始所有字符 d回车: 删除当前行以及下一行 复制 yl： 复制光标所在的字符 nyl： 复制光标为首的 n 个字符 yw： 复制光标到词尾的字符 nyw： 复制 n 个字符 yy： 复制当前行 nyy： 复制 n 行 剪切 dd： 剪切当前行 ndd： 剪切 n 行 粘贴 p： 在光标之后粘贴 P： 在光标之前粘贴 撤销及重复 u： 撤销改动 .： 重复上一命令 ctrl+r | U： 重做 2. 插入模式 i： 在光标之前插入 a： 在光标之后插入 I： 在行首插入 A： 在行尾插入 o： 在当前行下面新开一行，插入 O： 在当前行上面新开一行，插入 cc： 删除当前行，并进入插入模式 s： 删除光标所在位置的字符并进入插入模式 3. 末行模式搜索 :/search： 从当前光标向下搜索指定字符串 :?search： 从当前行开始向上搜索指定字符串 n： 向下重复搜索 N： 向上重复搜索 替换 :s/source/replacement/： 将当前行出现第一个源字符串替换掉 :s/source/replacement/g： 将当前行的所有匹配字符串都替换掉 :1,2s/source/replacement/g： 将 1 到 2 行（包括 1 和 2 行）中的所有匹配字符串都替换 :1,$s/source/replacement/g： 将 1 行到最后一行的所有匹配字符串替换 :%s/source/replacement/g： 将文件中所有匹配字符串替换 :%s/source/replacement/gc： 每次替换之前都需要确认 复制 :1,2 co 3： 将 1 到 2 行之间的内容复制到第 3 行下面 :1,2 m 3： 将 1 到 2 行之间的内容移动到第 3 行下面 删除 :1,2 d： 删除 1 到 2 行之间的所有内容 :%d | :1,$d： 删除全部内容 保存 :w： 保存 :w!： 强制保存 :w /filename： 另存为 1,2w /filename： 将 1 到 2 行之间的内容另存为 :x | :wq： 保存并退出 :q： 退出不保存 :q!： 强制退出不保存 :wq!： 强制保存并退出 :e!： 放弃此次修改 选项 :set number： 是指是否显示行号 :set list： 显示制表符和行尾标志 :hlsearch： 是否开启高亮查找结果 4. 配置更多配置可以参考 learnvimscriptthehardway 我的配置： 12345678910111213141516171819202122232425" = 设置行号和选中行set numberset cursorline" = 设置 tab 宽度为 4set tabstop=4set softtabstop=4set smartindentset shiftwidth=4" = 设置编码格式set encoding=utf-8set fileencoding=utf-8set fileencodings=ucs-bom,utf-8,chinese,latin1" = 高亮代码syntax on" = 选中行在屏幕中上下至少有 5 行set scrolloff=5" = 在插入模式中，光标的样式变成和 word 一样的一个竖线 |let &amp;t_SI = "\&lt;Esc&gt;]50;CursorShape=1\x7"let &amp;t_SR = "\&lt;Esc&gt;]50;CursorShape=2\x7"let &amp;t_EI = "\&lt;Esc&gt;]50;CursorShape=0\x7"]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>tool</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux 常用命令之文本处理工具]]></title>
    <url>%2F2019%2F08%2F27%2Flinux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%B9%8B%E6%96%87%E6%9C%AC%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[linux 中常用的命令行工具，对文本进行处理，有 grep、cut、sort、uniq、tee、diff、paste、tr，其中最常用的就是 grep 和 cut 还有更牛逼的 ack。 1. grep grep（global search regular expression(RE) and print out the line，全面搜索正则表达式并把行打印出来） 是一种强大的文本搜索工具，他能使用正则表达式搜索文本，并把匹配的行打印出来。 用于过滤/搜索的特定字符 可用正则表达式配合使用，使用十分灵活 常用选项1234567891011121314151617-i # 不区分大小写-v # 查找不包含指定行的内容，反向选择-w # 按单词搜索-o # 打印匹配关键字-n # 显示行号-r # 逐层遍历目录查找-A # 显示匹配行以及其后面多少行-B # 显示匹配行以及其前面多少行-C # 显示匹配行以及其前后多少行-l # 只列出匹配的文件名-L # 列出不匹配的文件名-e # 使用正则表达式-E # 使用扩展正则匹配^key # 以关键字开头key$ # 以关键字结尾^$ # 匹配空行--color=auto # 将关键字加上颜色 正则表达式12345678910111213141516^ # 锁定行的开始$ # 锁定行的结尾. # 匹配一个非换行符的字符* # 0 个或多个.* # 任意字符[] # 一个范围内的字符，[Gg] 表示 G 或 g[^] # 一定范围内以什么开头\(..\) # 标记匹配符，\(love\)，此时 love 就被标记为 1\&lt; # 锁定单词的开始，匹配包含这个单词的行\&gt; # 锁定单词的结尾x\&#123;m\&#125; # 重复字符 x，重复了 m 次x\&#123;m,\&#125; # 至少重复了 m 次x\&#123;m,n\&#125; # 重复了 m～n 次\w # 匹配文字和字符串，即 [A-Za-z0-9]\W # \w 的取反形式，匹配一个或多个非单词字符，比如点句号等\b # 单词锁定符，如 \bjojo\b 表示只匹配 jojo 常见用法在文件中搜索一个单词，命令会返回一个包含 “match_pattern” 的文本行： 12$ grep match_pattern file_name$ grep "match_pattern" file_name 在多个文件中查找： 1$ grep "match_pattern" file_1 file_2 file3 ... 输出除了目标之外的所有行： 1$ grep -v "match_pattern" file_name 使用正则表达式： 12$ grep -E "[1-9]+"$ egrep "[1-9]+" 只输出文件中匹配的部分，主要配合正则使用： 1$ echo this is a test line. | grep -o -E "[a-z]+\." 统计文件或文件中包含匹配字符串的行数： 1$ grep -c "text" file_name 输出包含匹配字符串的行数： 12$ grep "text" -n file_name$ cat file_name | grep "text" -n 打印样式匹配所位于的字符或字节偏移： 1$ echo gun is not unix | grep -b -o "not" 搜索多个文件并查找匹配文本在哪些文件中： 1$ grep -l "text" file1 file2 file3 ... 递归搜索文件在多级目录中对文本进行递归搜索： 1$ grep "text" ./ -r -n 忽略大小写： 1$ echo "hello world" | grep -i "HELLO" 选项 -e 可以匹配多个样式： 1$ echo this is a text line | grep -e "is" -e "line" -o 也可以使用 -f 来匹配多个样式，使用的是样式文件： 1234$ cat patfileaaabbb$ echo aaa bbb ccc ddd eee | grep -f patfile -o 在 grep 搜索结果中包括或排除指定文件： 12345678# 只在目录中所有的 .php 和 .html 文件中递归搜索字符 "main()"$ grep "main()" . -r --include *.&#123;php,html&#125;# 在搜索结果中排除所有的 README 文件$ grep "main()" . -r --exclude "README"# 在搜索结果中排除 filelist 文件列表中的文件$ grep "main()" . -r --exclude-from filelsit 使用 0 值字节的后缀的 grep 与 xargs： 1234567# 测试文件$ echo "aaa" &gt; file1$ echo "bbb" &gt; file2$ echo "ccc" &gt; file3$ grep "aaa" file* -lZ | xargs -0 rm# 执行后会删除 file1 和 file3，grep 的 -Z 选项是用来指定以 0 值字节为终结的文件名，xargs -0 读取输入并用 0 值字节终结符分割文件名，然后删除匹配文件 显示匹配到行之前多少行，之后多少行： 1234$ seq 10 | grep 5 -A 3$ seq 10 | grep 5 -B 3$ seq 10 | grep 5 -C 3# 如果匹配结果有多个，中间会以 -- 作为分隔符 2. cut 用于列的截取 用于连接文件 常用选项123-c # 以字符为单位进行分割截取-d # 自定义分隔符，默认为制表符 \t-f # 与 -d 一起使用，指定截取哪个区域 常见用法123456$ cut -d: -f1 test.text # 以 : 为分隔符的第一列内容$ cut -d: -f1,6,7 test.text # 以 : 为分隔符，第 1、6、7 列的内容$ cut -c4 test.txt # 截取文件每行中的第 4 个字符$ cut -c1-4 test.txt # 截取每行中的 1~4 个字符$ cut -c5- test.txt # 截取每行从第 5 个字符开始$ cut -c-2 test.txt # 截取每行的前面两个字符 实例1234567891011$ cat test.txtNo Name Mark Precent01 tom 69 9102 jack 71 8703 alex 68 98$ cut -f2,3 test.txtName Marktom 69jack 71alex 68]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>shell</tag>
        <tag>命令行</tag>
      </tags>
  </entry>
</search>
